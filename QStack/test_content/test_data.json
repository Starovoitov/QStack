[{"model": "stack.user", "fields": {"password": "pbkdf2_sha256$100000$ER2caXVdQ4Wx$dSlz10sFfm5W3d1xto9yKseYXvIFPHPGH2HNT5N+00M=", "last_login": "2018-10-22T23:10:56Z", "is_superuser": true, "username": "root", "first_name": "", "last_name": "", "email": "artem.starovoitov@mail.ru", "is_staff": true, "date_joined": "2018-10-20T19:13:25Z", "image": "photos/1/test_avatar5.jpg", "is_active": true, "groups": [], "user_permissions": []}}, {"model": "stack.user", "fields": {"password": "pbkdf2_sha256$100000$BAdYsbqYU1JI$4KmQwOUJW/hSMgu7RDvaWDRVpPIIO3VnQ2tTDc7id74=", "last_login": "2018-10-21T23:43:52.463Z", "is_superuser": false, "username": "user54", "first_name": "", "last_name": "", "email": "u1@mail.com", "is_staff": false, "date_joined": "2018-10-21T23:12:49.958Z", "image": "", "is_active": true, "groups": [], "user_permissions": []}}, {"model": "stack.user", "fields": {"password": "pbkdf2_sha256$100000$2WzkF8GLWcky$gIB4eodnU+HZdPk0IohxH03UnSZTAj+SiCdlzt3sFRc=", "last_login": "2018-10-23T12:24:44.605Z", "is_superuser": false, "username": "test_user", "first_name": "", "last_name": "", "email": "test@mail.com", "is_staff": false, "date_joined": "2018-10-22T23:46:54.913Z", "image": "photos/None/test_avatar_ABRPluI.jpg", "is_active": true, "groups": [], "user_permissions": []}}, {"model": "stack.user", "fields": {"password": "pbkdf2_sha256$100000$nhNe85kYkL0I$rE8kCcHBbQy+M0rZgRJlFtLwatxsJFu45C/UkfV6IsI=", "last_login": null, "is_superuser": false, "username": "u2", "first_name": "", "last_name": "", "email": "u2@mail.com", "is_staff": false, "date_joined": "2018-10-23T09:26:54.042Z", "image": "photos/None/test_avatar2.png", "is_active": true, "groups": [], "user_permissions": []}}, {"model": "stack.user", "fields": {"password": "pbkdf2_sha256$100000$J44bMih4jG1P$migCUDFJXxzMszX1zTC3kWgwuS3dB1mO8Qn5q65Sph4=", "last_login": null, "is_superuser": false, "username": "u3", "first_name": "", "last_name": "", "email": "u3@mail.com", "is_staff": false, "date_joined": "2018-10-23T10:19:26.532Z", "image": "photos/None/ttt.jpeg", "is_active": true, "groups": [], "user_permissions": []}}, {"model": "stack.user", "fields": {"password": "pbkdf2_sha256$100000$YflVxg7UuAzp$PsRjH/gtN9lM5y3YIDtNB3BaUP+wy28wbeBs1BY62Ok=", "last_login": null, "is_superuser": false, "username": "u4", "first_name": "", "last_name": "", "email": "u4@gmail.com", "is_staff": false, "date_joined": "2018-10-23T10:19:52.601Z", "image": "", "is_active": true, "groups": [], "user_permissions": []}}, {"model": "stack.user", "fields": {"password": "pbkdf2_sha256$100000$jN8ALcmIYLPC$to22r/xGGhT3X0GxadT95LOTumVB/9GCulhLNmZTO6k=", "last_login": null, "is_superuser": false, "username": "u5", "first_name": "", "last_name": "", "email": "u5@mail.com", "is_staff": false, "date_joined": "2018-10-23T10:20:17Z", "image": "photos/35/test_avatar4.png", "is_active": true, "groups": [], "user_permissions": []}}, {"model": "stack.answer", "pk": 1, "fields": {"content": "\r\nYou are a victim of branch prediction fail.\r\n\r\nWhat is Branch Prediction?\r\nConsider a railroad junction:\r\n\r\nLicensed Image Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.\r\n\r\nNow for the sake of argument, suppose this is back in the 1800s - before long distance or radio communication.\r\n\r\nYou are the operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately.\r\n\r\nTrains are heavy and have a lot of inertia. So they take forever to start up and slow down.\r\n\r\nIs there a better way? You guess which direction the train will go!\r\n\r\nIf you guessed right, it continues on.\r\nIf you guessed wrong, the captain will stop, back up, and yell at you to flip the switch. Then it can restart down the other path.\r\nIf you guess right every time, the train will never have to stop.\r\nIf you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting.\r\n\r\nConsider an if-statement: At the processor level, it is a branch instruction:\r\n\r\nimage2\r\n\r\nYou are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.\r\n\r\nModern processors are complicated and have long pipelines. So they take forever to \"warm up\" and \"slow down\".\r\n\r\nIs there a better way? You guess which direction the branch will go!\r\n\r\nIf you guessed right, you continue executing.\r\nIf you guessed wrong, you need to flush the pipeline and roll back to the branch. Then you can restart down the other path.\r\nIf you guess right every time, the execution will never have to stop.\r\nIf you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting.\r\n\r\nThis is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.\r\n\r\nSo how would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every 3 times, you guess the same...\r\n\r\nIn other words, you try to identify a pattern and follow it. This is more or less how branch predictors work.\r\n\r\nMost applications have well-behaved branches. So modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.\r\n\r\nFurther reading: \"Branch predictor\" article on Wikipedia.\r\n\r\nAs hinted from above, the culprit is this if-statement:\r\nif (data[c] >= 128)\r\n    sum += data[c];\r\nNotice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.\r\n\r\nThis is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.\r\n\r\nQuick visualization:\r\n\r\nT = branch taken\r\nN = branch not taken\r\n\r\ndata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...\r\nbranch = N  N  N  N  N  ...   N    N    T    T    T  ...   T    T    T  ...\r\n\r\n       = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)\r\nHowever, when the data is completely random, the branch predictor is rendered useless because it can't predict random data. Thus there will probably be around 50% misprediction. (no better than random guessing)\r\n\r\ndata[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118,  14, 150, 177, 182, 133, ...\r\nbranch =   T,   T,   N,   T,   T,   T,   T,  N,   T,   N,   N,   T,   T,   T,   N  ...\r\n\r\n       = TTNTTTTNTNNTTTN ...   (completely random - hard to predict)\r\nSo what can be done?\r\n\r\nIf the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.\r\n\r\nReplace:\r\n\r\nif (data[c] >= 128)\r\n    sum += data[c];\r\nwith:\r\n\r\nint t = (data[c] - 128) >> 31;\r\nsum += ~t & data[c];\r\nThis eliminates the branch and replaces it with some bitwise operations.\r\n\r\n(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of data[].)\r\n\r\nBenchmarks: Core i7 920 @ 3.5 GHz\r\n\r\nC++ - Visual Studio 2010 - x64 Release\r\n\r\n//  Branch - Random\r\nseconds = 11.777\r\n\r\n//  Branch - Sorted\r\nseconds = 2.352\r\n\r\n//  Branchless - Random\r\nseconds = 2.564\r\n\r\n//  Branchless - Sorted\r\nseconds = 2.587\r\nJava - Netbeans 7.1.1 JDK 7 - x64\r\n\r\n//  Branch - Random\r\nseconds = 10.93293813\r\n\r\n//  Branch - Sorted\r\nseconds = 5.643797077\r\n\r\n//  Branchless - Random\r\nseconds = 3.113581453\r\n\r\n//  Branchless - Sorted\r\nseconds = 3.186068823\r\nObservations:\r\n\r\nWith the Branch: There is a huge difference between the sorted and unsorted data.\r\nWith the Hack: There is no difference between sorted and unsorted data.\r\nIn the C++ case, the hack is actually a tad slower than with the branch when the data is sorted.\r\nA general rule of thumb is to avoid data-dependent branching in critical loops. (such as in this example)", "pub_date": "2018-10-23T09:31:42.078Z", "correctness": false, "question": 1, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 2, "fields": {"content": "\r\n73\r\ndown vote\r\nBesides the fact that the branch prediction may slow you down, a sorted array has another advantage:\r\n\r\nYou can have a stop condition instead of just checking the value, this way you only loop over the relevant data, and ignore the rest.\r\nThe branch prediction will miss only once.\r\n\r\n // sort backwards (higher values first)\r\n std::sort(data, data + arraySize, std::greater<int>());\r\n\r\n for (unsigned c = 0; c < arraySize; ++c) {\r\n       if (data[c] < 128) {\r\n              break;\r\n       }\r\n       sum += data[c];               \r\n }", "pub_date": "2018-10-23T09:32:11.358Z", "correctness": false, "question": 1, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 3, "fields": {"content": "Sorted arrays are processed faster than an unsorted array, due to phenomena called the branch prediction.\r\n\r\nBranch predictor is a digital circuit (in computer architecture) trying to predict which way a branch will go, improving the flow in the instruction pipeline. The circuit/computer predicts the next step and executes it.\r\n\r\nMaking a wrong prediction leads to going back to the previous step, and executing with another prediction. Assuming the prediction is correct, the code will continue to the next step. Wrong prediction results in repeating the same step, until correct prediction occurs.\r\n\r\nThe answer to your question is very simple.\r\n\r\nIn an unsorted array, the computer makes multiple predictions, leading to an increased chance of errors. Whereas, in sorted, the computer makes fewer predictions reducing the chance of errors. Making more prediction requires more time.\r\n\r\nSorted Array: Straight Road\r\n\r\n____________________________________________________________________________________\r\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \r\nTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\r\nUnsorted Array: Curved Road\r\n\r\n______   ________\r\n|     |__|\r\nBranch prediction: Guessing/predicting which road is straight and following it without checking\r\n\r\n___________________________________________ Straight road\r\n |_________________________________________|Longer road\r\nAlthough both the roads reach the same destination, the straight road is shorter, and the other is longer. If then you choose the other by mistake, there is no turning back, and so you will waste some extra time if you choose the longer road. This is similar to what happens on the computer, and I hope this helped you understand better.\r\n\r\nUpdate: After what @Simon_Weaver said, I want to add another fact that... \"it doesn\u2019t make fewer predictions - it makes fewer incorrect predictions. It still has to predict for each time through the loop.\"", "pub_date": "2018-10-23T09:32:45.478Z", "correctness": false, "question": 1, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 4, "fields": {"content": "You can use the format method of the DateTime class:\r\n\r\n$date = new DateTime('2000-01-01');\r\n$result = $date->format('Y-m-d H:i:s');\r\nIf format fails for some reason, it will return FALSE. In some applications, it might make sense to handle the failing case:\r\n\r\nif ($result) {\r\n  echo $result;\r\n} else { // format failed\r\n  echo \"Unknown Time\";\r\n}", "pub_date": "2018-10-23T09:34:18.753Z", "correctness": false, "question": 2, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 5, "fields": {"content": "The simplest way I found is:\r\n\r\n$date   = new DateTime(); //this returns the current date time\r\n$result = $date->format('Y-m-d-H-i-s');\r\necho $result . \"<br>\";\r\n$krr    = explode('-', $result);\r\n$result = implode(\"\", $krr);\r\necho $result;", "pub_date": "2018-10-23T09:34:25.131Z", "correctness": false, "question": 2, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 6, "fields": {"content": "\r\n11\r\ndown vote\r\nThere are some predefined formats in date_d.php to use with format like:\r\n\r\ndefine ('DATE_ATOM', \"Y-m-d\\TH:i:sP\");\r\ndefine ('DATE_COOKIE', \"l, d-M-y H:i:s T\");\r\ndefine ('DATE_ISO8601', \"Y-m-d\\TH:i:sO\");\r\ndefine ('DATE_RFC822', \"D, d M y H:i:s O\");\r\ndefine ('DATE_RFC850', \"l, d-M-y H:i:s T\");\r\ndefine ('DATE_RFC1036', \"D, d M y H:i:s O\");\r\ndefine ('DATE_RFC1123', \"D, d M Y H:i:s O\");\r\ndefine ('DATE_RFC2822', \"D, d M Y H:i:s O\");\r\ndefine ('DATE_RFC3339', \"Y-m-d\\TH:i:sP\");\r\ndefine ('DATE_RSS', \"D, d M Y H:i:s O\");\r\ndefine ('DATE_W3C', \"Y-m-d\\TH:i:sP\");\r\nUse like this:\r\n\r\n$date = new \\DateTime();\r\n$string = $date->format(DATE_RFC2822);", "pub_date": "2018-10-23T09:34:32.267Z", "correctness": false, "question": 2, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 7, "fields": {"content": "echo date_format($date,\"Y/m/d H:i:s\");", "pub_date": "2018-10-23T09:34:41.505Z", "correctness": false, "question": 2, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 8, "fields": {"content": "Its worked for me\r\n\r\n$start_time   = date_create_from_format('Y-m-d H:i:s', $start_time);\r\n$current_date = new DateTime();\r\n$diff         = $start_time->diff($current_date);\r\n$aa           = (string)$diff->format('%R%a');\r\necho gettype($aa);", "pub_date": "2018-10-23T09:34:52.433Z", "correctness": false, "question": 2, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 9, "fields": {"content": "Shorter way using list. And you can do what you want with each date component.\r\n\r\nlist($day,$month,$year,$hour,$min,$sec) = explode(\"/\",date('d/m/Y/h/i/s'));\r\necho $month.'/'.$day.'/'.$year.' '.$hour.':'.$min.':'.$sec;", "pub_date": "2018-10-23T09:34:59.067Z", "correctness": false, "question": 2, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 10, "fields": {"content": "You used the string method startswith, but there is also endswith...\r\n\r\nI also took the liberty of moving the constant requested beginning out of the loop,\r\n\r\ntarget_ip = \"10.10.100.1\"\r\nbegins = \"Nmap scan report for\"\r\n\r\nfhand = open('ScanTest.txt','r')\r\nfor line in fhand:\r\n    line = line.rstrip()\r\n    if line.startswith(begins) and line.endswith(target_ip):\r\n        print(line)", "pub_date": "2018-10-23T09:37:38.602Z", "correctness": false, "question": 4, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 11, "fields": {"content": "I think you need to change the line \u2026\r\n\r\nif line.startswith('Nmap scan report for')and (target_ip):\r\n\u2026 to \u2026\r\n\r\nif line.startswith('Nmap scan report for') and (line.split(' ')[4] == target_ip):", "pub_date": "2018-10-23T09:37:48.494Z", "correctness": false, "question": 4, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 12, "fields": {"content": "Assuming your list of dicts is stored as variable l, you can use next() with a generator expression like this, which returns the first dict whose name key is foo:\r\n\r\nnext(d for d in l if d['name'] == 'foo')\r\nThis will otherwise raise StopIteration if there is no dict in l with a name key that equals foo", "pub_date": "2018-10-23T09:39:49.990Z", "correctness": false, "question": 6, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 13, "fields": {"content": "Try this simple example.\r\n\r\ndata = [\r\n    {\r\n        \"name\": \"hello\",\r\n        \"value\": \"world\"\r\n    },\r\n    {\r\n        \"name\": \"foo\",\r\n        \"value\": \"bar\"\r\n    }\r\n  ]\r\n\r\n\r\nfor item in data:\r\n    if item['name'] == 'foo':\r\n        print(item)\r\nOutput:\r\n\r\n{'name': 'foo', 'value': 'bar'}", "pub_date": "2018-10-23T09:39:57.804Z", "correctness": false, "question": 6, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 14, "fields": {"content": "You can zip the dictionary items with letter_frequency and then enumerate its output so that you can use the indices to determine if you want to output the updated values or not in a dict comprehension:\r\n\r\nn = int(input('Enter how many values to update: '))\r\nprint({k: l if i < n else k for i, ((k, _), l) in enumerate(zip(dictionary.items(), letter_frequency))})\r\nSample input/output:\r\n\r\nEnter how many values to update: 3\r\n{'s': 'e', 'o': 't', 'c': 'a', 'w': 'w', 'g': 'g', 'm': 'm', 't': 't', 'k': 'k', 'e'", "pub_date": "2018-10-23T09:40:43.411Z", "correctness": false, "question": 7, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 15, "fields": {"content": "Try this simple code:\r\n\r\nnum= int(input(\"Enter how many values to update:\" ))\r\nfor i,key in enumerate (dictionary.keys()):\r\n    if i < num:\r\n        dictionary[key] = letter_frequency[i]\r\n    else:\r\n        dictionary[key] = key\r\nCheck and let me know if it doesn't suit your need.", "pub_date": "2018-10-23T09:40:56.050Z", "correctness": false, "question": 7, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 16, "fields": {"content": "You haven't provided and exit path from the recursive loop. A return statement should do the trick.\r\n\r\n    (...)\r\n    while True:\r\n        if line.rstrip().endswith('\"\"\"'):\r\n            line = infile.readline()\r\n            return find_comment(infile, line)\r\n        else:\r\n            line = infile.readline()", "pub_date": "2018-10-23T09:41:39.424Z", "correctness": false, "question": 8, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 17, "fields": {"content": "while True is an infinite loop. You need to break once you're done.", "pub_date": "2018-10-23T09:41:50.572Z", "correctness": false, "question": 8, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 18, "fields": {"content": "not line_t.startswith('\"\"\"') or not line_t.startswith('#')\r\nThis expression evaluates to True no matter what string line_t denotes. Do you want 'and' instead of 'or'? Your question isn't clear to me.", "pub_date": "2018-10-23T09:41:57.004Z", "correctness": false, "question": 8, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 19, "fields": {"content": "if not line_t.startswith('\"\"\"') or not line_t.startswith('#'):\r\nThis if will always be satisfied -- either the line doesn't start with \"\"\", or it doesn't start with # (or both). You probably meant to use and where you used or.", "pub_date": "2018-10-23T09:42:02.555Z", "correctness": false, "question": 8, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 20, "fields": {"content": "As long as lines start or end with a comment, the code below should work.\r\n\r\nHowever, keep in mind that the docstrings can start or end in the middle of a line of code.\r\n\r\nAlso, you'll need to code for triple single-quotes as well as docstrings assigned to variables which aren't really comments.\r\n\r\nDoes this get you closer to an answer?\r\n\r\ndef count_loc(infile):\r\n  skipping_comments = False\r\n  loc = 0 \r\n  for line in infile:\r\n    # Skip one-liners\r\n    if line.strip().startswith(\"#\"): continue\r\n    # Toggle multi-line comment finder: on and off\r\n    if line.strip().startswith('\"\"\"'):\r\n      skipping_comments = not skipping_comments\r\n    if line.strip().endswith('\"\"\"'):\r\n      skipping_comments = not skipping_comments\r\n      continue\r\n    if skipping_comments: continue\r\n    print line,", "pub_date": "2018-10-23T09:42:08.964Z", "correctness": false, "question": 8, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 21, "fields": {"content": "The only language I can think of to attempt such a mid-stream change would be Perl. Of course, Python is beating Perl to that particular finish line by releasing first. It should be noted, however, that Perl's changes are much more extensive than Python's and likely will be harder to detangle.\r\n\r\n(There's a price for Perl's \"There's More Than One Way To Do It\" philosophy.)\r\n\r\nThere are examples like the changes from version to version of .NET-based languages (ironic, considering the whole point of .NET was supposed to be API stability and cross-platform compatibility). However, I would hardly call those languages \"mature\"; it's always been more of a design-on-the-go, build-the-plane-as-we-fly approach to things.\r\n\r\nOr, as I tend to think of it, most languages come from either \"organic growth\" or \"engineered construction.\" Perl is the perfect example of organic growth; it started as a fancy text processing tool ala awk/sed and grew into a full language.\r\n\r\nPython, on the other hand, is much more engineered. Spend a bit of time wandering around the extensive whitepapers on their website to see the extensive debate that goes into every even minor change to the language's syntax and implementation.\r\n\r\nThe idea of making these sorts of far-reaching changes is somewhat new to programming languages because programming languages themselves have changed in nature. It used to be that programming methodologies changed only when a new processor came out that had a new instruction set. The early languages tended to either be so low-level and married to assembly language (e.g. C) or so utterly dynamic in nature (Forth, Lisp) that such a mid-stream change wouldn't even come up as a consideration.\r\n\r\nAs to whether or not the changes are good ones, I'm not sure. I tend to have faith in the people guiding Python's development, however; the changes in the language thus far have been largely for the better.\r\n\r\nI think in the days to come the Global Interpreter Lock will prove more central than syntax changes. Though the new multiprocessor library might alleviate most of that.", "pub_date": "2018-10-23T09:42:49.049Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 22, "fields": {"content": "The price of insisting on near-absolute backwards compatibility is just too high. Spend two minutes programming in C++ if you want to see why.", "pub_date": "2018-10-23T09:43:00.200Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 23, "fields": {"content": "The python team has worked very hard to make the lack of backward compatibility as painless as possible, to the point where the 2.6 release of python was created with a mind towards a painless upgrade process. Once you have upgraded to 2.6 there are scripts that you can run that will move you to 3.0 without issue.", "pub_date": "2018-10-23T09:43:05.751Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 24, "fields": {"content": "It's worth mentioning that backward compatibility incurs costs of its own. In some cases it's almost impossible to evolve a language in the ideal way if 100% backward compatibility is required. Java's implementation of generics (which erases type information at compile-time in order to be backwardly-compatible) is a good example of how implementing features with 100% backward compatibility can result in a sub-optimal language feature.\r\n\r\nSo loosely speaking, it can come down to a choice between a poorly implemented new feature that's backwardly compatible, or a nicely implemented new feature that's not. In many cases, the latter is a better choice, particularly if there are tools that can automatically translate incompatible code.", "pub_date": "2018-10-23T09:43:18.394Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 25, "fields": {"content": "I think there are many examples of backward compatibility breakages. Many of the languages that did this were either small or died out along the way.\r\n\r\nMany examples of this involved renaming the language.\r\n\r\nAlgol 60 and Algol 68 were so different that the meetings on Algol 68 broke up into factions. The Algol 68 faction, the Pascal faction and the PL/I faction.\r\n\r\nWirth's Pascal morphed into Modula-3. It was very similar to pascal -- very similar syntax and semantics -- but several new features. Was that really a Pascal-2 with no backward compatibility?\r\n\r\nThe Lisp to Scheme thing involved a rename.\r\n\r\nIf you track down a scan of the old B programming language manual, you'll see that the evolution to C looks kind of incremental -- not radical -- but it did break compatibility.\r\n\r\nFortran existed in many forms. I don't know for sure, but I think that Digital's Fortran 90 for VAX/VMS wasn't completely compatible with ancient Fortran IV programs.\r\n\r\nRPG went through major upheavals -- I think that there are really two incompatible languages called RPG.\r\n\r\nBottom Line I think that thinking and learning are inevitable. You have three responses to learning the limitations of a language.\r\n\r\nInvent a new language that's utterly incompatible.\r\n\r\nIncremental chagne until you are forced to invent a new language.\r\n\r\nBreak compatibility in a controlled, thoughtful way.\r\n\r\nI think that #1 and #2 are both coward's ways out. Chucking the old is easier than attempting to preserve it. Preserving every nuanced feature (no matter how bad) is a lot of work, some of it of little or no value.\r\n\r\nCommercial enterprises opt for cowardly approaches in the name of \"new marketing\" or \"preserving our existing customers\". That's why commercial software ventures aren't hot-beds of innovation.\r\n\r\nI think that only open-source projects can be embrace innovation in the way that the Python community is tackling this change.", "pub_date": "2018-10-23T09:43:32.236Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 26, "fields": {"content": "Wouldn't VB6 to VB.net be the biggest example of this? Or do you all consider them two separate languages?", "pub_date": "2018-10-23T09:43:39.616Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 27, "fields": {"content": "C# and the .NET framework broke compatibility between versions 1.0 and 1.1 as well as between 1.1 and 2.0. Running applications in different versions required having multiple versions of the .NET runtime installed.\r\n\r\nAt least they did include an upgrade wizard to upgrade source from one version to the next (it worked for most of our code).", "pub_date": "2018-10-23T09:43:45.966Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 28, "fields": {"content": "In the Lisp world it has happened a few times. of course, the language is so dynamic that usually evolution is simply deprecating part of the standard library and making standard another part.\r\n\r\nalso, Lua 4 to 5 was pretty significant; but the language core is so minimal that even wide-reaching changes are documented in a couple of pages.", "pub_date": "2018-10-23T09:43:55.505Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 29, "fields": {"content": "First, here is a video talk about the changes Python will go through. Second, changes are no good. Third, I for one welcome evolution and believe it is necessary.", "pub_date": "2018-10-23T09:44:03.774Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 30, "fields": {"content": "Perl 6 is also going through this type of split right now. Perl 5 programs won't run directly on Perl 6, but there will be a translator to translate the code into a form that may work (I don't think it can handle 100% of the cases).\r\n\r\nPerl 6 even has its own article on Wikipedia.", "pub_date": "2018-10-23T09:44:12.615Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 31, "fields": {"content": "gcc regularly changes how it handles C++ almost every minor release. Of course, this is more a consequence of gcc tightening how they follow the rules, and less of C++ itself changing.", "pub_date": "2018-10-23T09:44:20.026Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 32, "fields": {"content": "The new version of the Ruby programming language will also break compatibility.\r\n\r\nAnd think of the libraries one might use: gtk, Qt, and so on (they also have incompatible versions).\r\n\r\nI think incompatibility is necessary sometimes (but not too often) to support progress.", "pub_date": "2018-10-23T09:44:28.996Z", "correctness": false, "question": 9, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 33, "fields": {"content": "Aha, you can pipe the 2to3 output to the patch command, which can write the modified file to a new file:\r\n\r\nmv something.py py2.6_something.py\r\n2to3 py2.6_something.py | patch -o something.py", "pub_date": "2018-10-23T09:45:05.553Z", "correctness": true, "question": 10, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 34, "fields": {"content": "2.x should be your codebase of active development, so 2to3 should really be run in a branch or temporary directory. I'm not sure why you'd want to have the 2.x and 3.x versions lying around in the same directory. distutils has a build_2to3 script that will run 2to3 on a 3.0 install.", "pub_date": "2018-10-23T09:45:15.353Z", "correctness": false, "question": 10, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 35, "fields": {"content": "Logically a lot of things like MIME-encoded mail messages, URLs, XML documents, and so on should be returned as bytes not strings. This could cause some consternation as the libraries start to be nailed down for Python 3 and people discover that they have to be more aware of the bytes/string conversions than they were for str/unicode ...", "pub_date": "2018-10-23T09:46:35.054Z", "correctness": true, "question": 11, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 36, "fields": {"content": "One of the great things about this question (and Python in general) is that you can just mess around in the interpreter! Python 3.0 rc1 is currently available for download.\r\n\r\n>>> import urllib.request\r\n>>> fh = urllib.request.urlopen('http://www.python.org/')\r\n>>> print(type(fh.read(100)))\r\n<class 'bytes'>", "pub_date": "2018-10-23T09:46:44.431Z", "correctness": false, "question": 11, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 37, "fields": {"content": "There will be a two-step dance here. See Python 3000 and You.\r\n\r\nStep 1 is to get running under 3.0.\r\n\r\nStep 2 is to rethink your API's to, perhaps, do something more sensible.\r\n\r\nThe most likely course is that the libraries will switch to unicode strings to remain as compatible as possible with how they used to work.\r\n\r\nThen, perhaps, some will switch to bytes to more properly implement the RFC standards for the various protocols.", "pub_date": "2018-10-23T09:46:52.925Z", "correctness": false, "question": 11, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 38, "fields": {"content": "If you want to help out with Python 3, find some libraries that haven't been ported yet and help port them. Projects that depend on these libraries can't make the switch until the libraries do.", "pub_date": "2018-10-23T09:48:16.501Z", "correctness": true, "question": 12, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 39, "fields": {"content": "Major point releases of languages take an exceedingly long time for wide adoption. Python 3 will not die -- eventually people will switch, but it may take many years.", "pub_date": "2018-10-23T09:48:26.884Z", "correctness": false, "question": 12, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 40, "fields": {"content": "PyPI lists a handful of packages ported to Python3 of which lxml and httplib2 are some of the prominent ones.", "pub_date": "2018-10-23T09:48:32.073Z", "correctness": false, "question": 12, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 41, "fields": {"content": "Bytes is an immutable sequence of integers (in the range 0<= to <256), therefore when you're accessing (a+b)[0] you're getting back an integer, exactly the same one you'd get by accessing a[0]. so when you're comparing sequence a to an integer (a+b)[0], they're naturally different.\r\n\r\nusing the slice notation you could however get a sequence back:\r\n\r\n>>> (a+b)[:1] == a         # 1 == len(a) ;)\r\nTrue\r\nbecause slicing returns bytes object.\r\n\r\nI would also advised to run 2to3 utility (it needs to be run with py2k) to convert some code automatically. It won't solve all your problems, but it'll help a lot.", "pub_date": "2018-10-23T09:49:06.009Z", "correctness": false, "question": 13, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 42, "fields": {"content": "A cleaner way to do this:\r\n\r\nfilter = ['a', 'b', 'c']\r\n\" \".join([\"item -%s\" % val for val in filter])\r\nThis works fine with large arrays, eg. filter = ['a'*1000] * 1000.", "pub_date": "2018-10-23T09:50:00.669Z", "correctness": true, "question": 14, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 43, "fields": {"content": "You can use join (I believe join is the same in Python 3.0):\r\n\r\n>>> l = ['a','b','c']\r\n>>> print ' item -'.join([''] + l)\r\n>>> ' item -a item -b item -c'\r\n\r\n>>> print ' item -'.join([''] + l).lstrip(' ') # eat the leading space\r\n>>> 'item -a item -b item -c'", "pub_date": "2018-10-23T09:50:09.442Z", "correctness": false, "question": 14, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 44, "fields": {"content": "grammar hasn't changed, some modules have.", "pub_date": "2018-10-23T09:50:47.443Z", "correctness": true, "question": 15, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 45, "fields": {"content": "For a simple HTTP web server, you can start with the WSGI reference implementation:\r\n\r\nwsgiref is a reference implementation of the WSGI specification that can be used to add WSGI support to a web server or framework. It provides utilities for manipulating WSGI environment variables and response headers, base classes for implementing WSGI servers, a demo HTTP server that serves WSGI applications,...\r\n\r\nModifying the example server to check the HTTP_HOST header, here is a simple app that responds, depending on the virtual host, with a different text. (Extending the example to use a configuration file is left as an exercise).\r\n\r\nimport wsgiref\r\nfrom wsgiref.simple_server import make_server\r\n\r\ndef my_app(environ,start_response):\r\n    from io import StringIO\r\n    stdout = StringIO()\r\n    host = environ[\"HTTP_HOST\"].split(\":\")[0]\r\n    if host == \"127.0.0.1\":\r\n        print(\"This is virtual host 1\", file=stdout)\r\n    elif host == \"localhost\":\r\n        print(\"This is virtual host 2\", file=stdout)\r\n    else:\r\n        print(\"Unknown virtual host\", file=stdout)\r\n\r\n    print(\"Hello world!\", file=stdout)\r\n    print(file=stdout)\r\n    start_response(b\"200 OK\", [(b'Content-Type',b'text/plain; charset=utf-8')])\r\n    return [stdout.getvalue().encode(\"utf-8\")]\r\n\r\ndef test1():\r\n    httpd = make_server('', 8000, my_app)\r\n    print(\"Serving HTTP on port 8000...\")\r\n\r\n    # Respond to requests until process is killed\r\n    httpd.serve_forever()", "pub_date": "2018-10-23T09:51:33.996Z", "correctness": true, "question": 16, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 46, "fields": {"content": "Virtual hosts work by obeying the Host: header in the HTTP request.\r\n\r\nJust read the headers of the request, and take action based on the value of the Host: header", "pub_date": "2018-10-23T09:51:44.563Z", "correctness": false, "question": 16, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 47, "fields": {"content": "Your code matched too much because a non empty string is always True, so your code printed all the lines beginning with \"Nmap...\".\r\n\r\nHow can you write correctly the test after and ? You used the string method startswith, but there is also endswith...\r\n\r\nI also took the liberty of moving the constant requested beginning out of the loop,\r\n\r\ntarget_ip = \"10.10.100.1\"\r\nbegins = \"Nmap scan report for\"\r\n\r\nfhand = open('ScanTest.txt','r')\r\nfor line in fhand:\r\n    line = line.rstrip()\r\n    if line.startswith(begins) and line.endswith(target_ip):\r\n        print(line)", "pub_date": "2018-10-23T09:53:22.923Z", "correctness": false, "question": 18, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 48, "fields": {"content": "I think you need to change the line \u2026\r\n\r\nif line.startswith('Nmap scan report for')and (target_ip):\r\n\u2026 to \u2026\r\n\r\nif line.startswith('Nmap scan report for') and (line.split(' ')[4] == target_ip):", "pub_date": "2018-10-23T09:53:31.004Z", "correctness": false, "question": 18, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 49, "fields": {"content": "Yes. There is a package called uncertainties. Install it: sudo pip install uncertainties\r\n\r\nExample:\r\n\r\n        from uncertainties import ufloat_fromstr\r\n        x = ufloat_fromstr(\"0.20+/-0.01\")\r\n        square = x**2\r\n        print square\r\nFor more info: https://pythonhosted.org/uncertainties/user_guide.html", "pub_date": "2018-10-23T09:54:15.933Z", "correctness": false, "question": 19, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 50, "fields": {"content": "You can do this efficiently with combining calendar.month_abbr and df[col].apply()\r\n\r\nimport calendar\r\ndf['Month'] = df['Month'].apply(lambda x: calendar.month_abbr[x])", "pub_date": "2018-10-23T09:56:16.104Z", "correctness": true, "question": 21, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 51, "fields": {"content": "One way of doing that is with the apply method in the dataframe but, to do that, you need a map to convert the months. You could either do that with a function / dictionary or with Python's own datetime.\r\n\r\nWith the datetime it would be something like:\r\n\r\ndef mapper(month):\r\n    date = datetime.datetime(2000, month, 1)  # You need a dateobject with the proper month\r\n    return date.strftime('%b')  # %b returns the months abbreviation, other options [here][1]\r\n\r\ndf['Month'].apply(mapper)\r\n\r\n\r\nIn a simillar way, you could build your own map for custom names. It would look like this:\r\n\r\nmonths_map = {01: 'Jan', 02: 'Feb'}\r\ndef mapper(month):\r\n    return months_map[month]\r\n\r\n\r\nObviously, you don't need to define this functions explicitly and could use a lambda directly in the apply method.", "pub_date": "2018-10-23T09:56:30.120Z", "correctness": false, "question": 21, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 52, "fields": {"content": "Use strptime and lambda function for this:\r\n\r\nfrom time import strptime\r\ndf['Month'] = df['Month'].apply(lambda x: strptime(x,'%b').tm_mon)", "pub_date": "2018-10-23T09:56:50.751Z", "correctness": false, "question": 21, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 53, "fields": {"content": "You can do this easily with a column apply.\r\n\r\nimport pandas as pd\r\n\r\ndf = pd.DataFrame({'client':['sss', 'yyy', 'www'], 'Month': ['02', '12', '06']})\r\n\r\nlook_up = {'01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr', '05': 'May',\r\n            '06': 'Jun', '07': 'Jul', '08': 'Aug', '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'}\r\n\r\ndf['Month'] = df['Month'].apply(lambda x: look_up[x])\r\ndf\r\n\r\n  Month client\r\n0   Feb    sss\r\n1   Dec    yyy\r\n2   Jun    www", "pub_date": "2018-10-23T09:56:58.122Z", "correctness": false, "question": 21, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 54, "fields": {"content": "Having tested all of these on a large dataset, I have found the following to be fastest:\r\n\r\nimport calendar\r\ndef month_mapping():\r\n    # I'm lazy so I have a stash of functions already written so\r\n    # I don't have to write them out every time. This returns the\r\n    # {1:'Jan'....12:'Dec'} dict in the laziest way...\r\n    abbrevs = {}\r\n    for month in range (1, 13):\r\n        abbrevs[month] = calendar.month_abbr[month]\r\n    return abbrevs\r\n\r\nabbrevs = month_mapping()\r\n\r\ndf['Month Abbrev'} = df['Date Col'].dt.month.map(mapping)", "pub_date": "2018-10-23T09:57:06.554Z", "correctness": false, "question": 21, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 55, "fields": {"content": "To delimit by a tab you can use the sep argument of to_csv:\r\n\r\ndf.to_csv(file_name, sep='\\t')\r\nTo use a specific encoding (e.g. 'utf-8') use the encoding argument:\r\n\r\ndf.to_csv(file_name, sep='\\t', encoding='utf-8')", "pub_date": "2018-10-23T09:58:07.305Z", "correctness": true, "question": 22, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 56, "fields": {"content": "I'd like to add something to what Andy Hayden already mentioned in his answer.\r\n\r\nWhen you are storing a DataFrame object into a csv file using the to_csv method, you probably wont be needing to store the preceding indices of each row of the DataFrame object.\r\n\r\nYou can avoid that by passing a False boolean value to index parameter.\r\n\r\nSomewhat like:\r\n\r\ndf.to_csv(file_name, encoding='utf-8', index=False)\r\nSo if your DataFrame object is something like:\r\n\r\n  Color  Number\r\n0   red     22\r\n1  blue     10\r\nThe csv file will store:\r\n\r\nColor,Number\r\nred,22\r\nblue,10\r\ninstead of (the case when the default value True was passed)\r\n\r\n,Color,Number\r\n0,red,22\r\n1,blue,10\r\nFound it worth sharing, Cheers! :-)", "pub_date": "2018-10-23T09:58:21.400Z", "correctness": false, "question": 22, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 57, "fields": {"content": "Something else you can try if you are having issues encoding to 'utf-8' and want to go cell by cell you could try the following.\r\n\r\nPython 2\r\n\r\n(Where \"df\" is your DataFrame object.)\r\n\r\nfor column in df.columns:\r\n    for idx in df[column].index:\r\n        x = df.get_value(idx,column)\r\n        try:\r\n            x = unicode(x.encode('utf-8','ignore'),errors ='ignore') if type(x) == unicode else unicode(str(x),errors='ignore')\r\n            df.set_value(idx,column,x)\r\n        except Exception:\r\n            print 'encoding error: {0} {1}'.format(idx,column)\r\n            df.set_value(idx,column,'')\r\n            continue\r\nThen try:\r\n\r\ndf.to_csv(file_name)\r\nYou can check the encoding of the columns by:\r\n\r\nfor column in df.columns:\r\n    print '{0} {1}'.format(str(type(df[column][0])),str(column))\r\nWarning: errors='ignore' will just omit the character e.g.\r\n\r\nIN: unicode('Regenexx\\xae',errors='ignore')\r\nOUT: u'Regenexx'\r\nPython 3\r\n\r\nfor column in df.columns:\r\n    for idx in df[column].index:\r\n        x = df.get_value(idx,column)\r\n        try:\r\n            x = x if type(x) == str else str(x).encode('utf-8','ignore').decode('utf-8','ignore')\r\n            df.set_value(idx,column,x)\r\n        except Exception:\r\n            print('encoding error: {0} {1}'.format(idx,column))\r\n            df.set_value(idx,column,'')\r\n            continue", "pub_date": "2018-10-23T09:58:39.001Z", "correctness": false, "question": 22, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 58, "fields": {"content": "Sometimes you face these problems if you specify UTF-8 encoding also. I recommend you to specify encoding while reading file and same encoding while writing to file. This might solve your problem.", "pub_date": "2018-10-23T09:58:46.659Z", "correctness": false, "question": 22, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 59, "fields": {"content": "it could be not the answer for this case, but as I had the same error-message with .to_csv I tried .toCSV('name.csv') and the error-message was different (\"'SparseDataFrame' object has no attribute 'toCSV'\"). So the problem was solved by turning dataframe to dense dataframe\r\n\r\ndf.to_dense().to_csv(\"submission.csv\", index = False, sep=',', encoding='utf-8')", "pub_date": "2018-10-23T09:58:56.678Z", "correctness": false, "question": 22, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 60, "fields": {"content": "df.to_csv('out.csv', sep=',')\r\nIt will work definitely.\r\n\r\nChange df to the name of your dataframe name and run.\r\n\r\nUse anaconda idle.", "pub_date": "2018-10-23T09:59:02.400Z", "correctness": false, "question": 22, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 61, "fields": {"content": "If you don't want the index.\r\n\r\n df.to_csv(\"out.csv\", index=False)", "pub_date": "2018-10-23T09:59:09.814Z", "correctness": false, "question": 22, "user": ["root"], "votes": -1}}, {"model": "stack.answer", "pk": 62, "fields": {"content": "Try this:\r\n\r\ndf = pd.concat([x for x in pd.read_sql(SQL_request,self.connection, chunksize=50000)", "pub_date": "2018-10-23T09:59:58.768Z", "correctness": false, "question": 24, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 63, "fields": {"content": "Use str.contains with apply in subset of DataFrame and then add any for test at least one True per row:\r\n\r\ncols = ['Parent', 'Child']\r\nmask = df[cols].apply(lambda x: x.str.contains('|'.join(substrings))).any(axis=1)\r\nOr chain boolenam mask together by | (bitwise OR):\r\n\r\nmask = (df['Parent'].str.contains('|'.join(substrings)) | \r\n        df['Child'].str.contains('|'.join(substrings)))\r\n\r\ndf = df[~mask]\r\nprint (df)\r\n  Parent   Child     score\r\n0  1stqw  Whoert  0.305125", "pub_date": "2018-10-23T10:00:41.973Z", "correctness": false, "question": 25, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 64, "fields": {"content": "You can concatenate and then use pd.Series.str.contains:\r\n\r\nL = ['Wor', 'Tas']\r\n\r\ndf = df[~(df['Parent'] + df['Child']).str.contains('|'.join(L))]\r\n\r\nprint(df)\r\n\r\n  Parent   Child     score\r\n0  1stqw  Whoert  0.305125\r\nFor efficiency / performance, see Pandas filtering for multiple substrings in series.", "pub_date": "2018-10-23T10:00:47.843Z", "correctness": true, "question": 25, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 65, "fields": {"content": "I apologize for my misunderstanding in the beginning. The following code snippet gives the results you wish\r\n\r\nfrom sklearn.metrics import mean_squared_error\r\nimport pandas\r\nimport math\r\nimport numpy\r\n\r\ndf = pandas.DataFrame(numpy.random.randint(0, 100, size = (100, 2)), columns = ['labels','predictions']).sort_values(by = 'labels', ascending = True)\r\ndef rmse(df):\r\n    return numpy.sqrt(mean_squared_error(df['labels'], df['predictions']))\r\n\r\noutput = df.groupby(numpy.floor(numpy.array(df['labels'] / 7))).apply(rmse)\r\nrmse_df = pandas.DataFrame({'bout': [str(int(output.index[i] * 7)) + ' - ' + str(int(output.index[i + 1] * 7)) for i in range(output.shape[0] - 1)], 'rmse': output.values[:-1]})\r\nYou can change the 7s in my code for your variable step if you want to dynamically change the step size", "pub_date": "2018-10-23T10:01:55.631Z", "correctness": false, "question": 26, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 66, "fields": {"content": "Not easy, but possible by comparing Series of tuples created by combinations of columns and comparing by isin:\r\n\r\ns11 = pd.Series(list(map(tuple, Df1[['User_id','User_name']].values.tolist())))\r\ns12 = pd.Series(list(map(tuple, Df2[['User_id','User_name']].values.tolist())))\r\n\r\ns21 = pd.Series(list(map(tuple, Df1[['User_id','User_phn']].values.tolist())))\r\ns22 = pd.Series(list(map(tuple, Df2[['User_id','User_phn']].values.tolist())))\r\n\r\n\r\nDf2.loc[~s12.isin(s11), 'User_name'] = 'Mismatch'\r\nDf2.loc[~s22.isin(s21), 'User_phn'] = 'Mismatch'\r\n\r\nprint (Df2)\r\n   User_id User_name  User_phn\r\n0        1      Alex  Mismatch\r\n1        2  Mismatch   4234123\r\n2        3     Bryan   5234123\r\n3        4  Mismatch  Mismatch\r\nSolution with merge with test unmatched pairs (missing values) by isna:\r\n\r\ns1 = Df2.merge(Df1, how='left', on=['User_id','User_name'], suffixes=('_',''))['User_phn']\r\nprint (s1)\r\n0    1234123.0\r\n1          NaN\r\n2    5234123.0\r\n3          NaN\r\nName: User_phn, dtype: float64\r\n\r\ns2 = Df2.merge(Df1, how='left', on=['User_id','User_phn'], suffixes=('_',''))['User_name']\r\nprint (s2)\r\n0      NaN\r\n1    Danny\r\n2    Bryan\r\n3      NaN\r\nName: User_name, dtype: object\r\n\r\nDf2.loc[s1.isna(), 'User_name'] = 'Mismatch'\r\nDf2.loc[s2.isna(), 'User_phn'] = 'Mismatch'\r\n\r\nprint (Df2)\r\n   User_id User_name  User_phn\r\n0        1      Alex  Mismatch\r\n1        2  Mismatch   4234123\r\n2        3     Bryan   5234123\r\n3        4  Mismatch  Mismatch", "pub_date": "2018-10-23T10:02:37.118Z", "correctness": false, "question": 27, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 67, "fields": {"content": "Hi Narayana Kandukuri,\r\n\r\nI guess my code may be simple, have a look.\r\n\r\nimport pandas as pd\r\n\r\ndf1 = pd.DataFrame([[1,'Alex',1234123],[2,'Danny',4234123],[3,'Bryan',5234123]],columns=['User_id','User_name','User_phn'])\r\ndf2 = pd.DataFrame([[1,'Alex',3234123],[2,'Chris',4234123],[3,'Bryan',5234123],[4,'Bexy',6234123]],columns=['User_id','User_name','User_phn'])\r\n\r\ntemp = df2[['User_id']] #Saving this for later use.\r\nBool_Data = (df1==df2[:df1.shape[0]]) #This will give you a boolean frame\r\ndf2 = df2[Bool_Data].fillna('mismatch') #Keep this boolean frame to df2\r\ndf2['User_id'] = temp['User_id'] #Assign the before temp.\r\n\r\ndf2 =\r\n   User_id User_name     User_phn\r\n0        1      Alex     mismatch\r\n1        2  mismatch     423412\r\n2        3     Bryan     523412\r\n3        4  mismatch     mismatch", "pub_date": "2018-10-23T10:02:43.800Z", "correctness": false, "question": 27, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 68, "fields": {"content": "I wrote the code and tackled the problem in a rather simple manner. I just compared every row of the two databases and did the comparison and appended resultant row to a result database. Let me know if this works.\r\n\r\nimport pandas as pd\r\ndata = [[1,'Alex','1234123'],[2,'Danny','4234123'],[3,'Bryan','5234123']]\r\ndf = pd.DataFrame(data,columns=['User_id','User_name','User_phn'])\r\nprint (df)\r\ndata = [[1,'Alex','3234123'],[2,'Chris','4234123'],[3,'Bryan','5234123'],[4,'Bexy','6234123']]\r\ndf_2 = pd.DataFrame(data,columns=['User_id','User_name','User_phn'])\r\nprint (df_2)\r\nl=max(len(df.index),len(df_2.index))\r\ndf_res = pd.DataFrame(columns=['User_id','User_name','User_phn'])\r\ndf_mat = df.as_matrix()\r\ndf_2_mat = df_2.as_matrix()\r\nfor i in range(0,l):\r\n    try:\r\n            arr=[]\r\n            arr.append(df_mat[i][0])\r\n            for k in range(1,3):\r\n                if df_mat[i][k] == df_2_mat[i][k]:\r\n                    arr.append(df_mat[i][k])\r\n                else:\r\n                    arr.append(\"Mismatch\")\r\n            df_res.loc[i] = arr\r\n\r\n    except:\r\n        df_res.loc[i] = [i+1,\"Mismatch\",\"Mismatch\"]\r\nprint(df_res)", "pub_date": "2018-10-23T10:02:54.740Z", "correctness": false, "question": 27, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 69, "fields": {"content": "This one liner should give you what you need.\r\n\r\nself.document[self.document.isin(mots)].melt()[\"value\"].dropna().values[0]\r\nIt applies your isin mask to the original df then finds the first non nan value using pd.melt and df.dropna", "pub_date": "2018-10-23T10:03:52.106Z", "correctness": false, "question": 28, "user": ["root"], "votes": -1}}, {"model": "stack.answer", "pk": 70, "fields": {"content": "The pd.DataFrame constructor does not accept a dictionary view as data. You can convert to list instead. Here's a minimal example:\r\n\r\nd = {'a': 1, 'b': 2, 'c': 3}\r\n\r\ndf = pd.DataFrame(d.values(), index=d.keys())\r\n# PandasError: DataFrame constructor not properly called!\r\n\r\ndf = pd.DataFrame(list(d.values()), index=d.keys())\r\n# Works!\r\nThe docs do suggest this:\r\n\r\ndata : numpy ndarray (structured or homogeneous), dict, or DataFrame\r\n\r\nEquivalently, you can use pd.DataFrame.from_dict, which accepts a dictionary directly:\r\n\r\ndf = pd.DataFrame.from_dict(d, orient='index')", "pub_date": "2018-10-23T10:05:01.187Z", "correctness": false, "question": 30, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 71, "fields": {"content": "found a solution: write the output to csv instead (anyway it can be opened in Excel as well)\r\n\r\ndata_wanted_all.to_csv(\"C:\\\\test-output.csv\", index=False)\r\npost here for in case some one encounters the same problem. let me know if this question shall be removed. :)", "pub_date": "2018-10-23T10:06:00.158Z", "correctness": false, "question": 32, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 72, "fields": {"content": "I don't think you can send both data and files in a multipart encoded file, so you can try making your data a \"file\" too. Something like this:\r\n\r\nfiles = {\r\n'data' : data,\r\n'document': open('file_name.pdf', 'rb')\r\n}\r\n\r\nheaders = {\r\n'Accept': \"application/pdf\",\r\n'Content-Type': \"multipart/form-data\",\r\n'Cache-Control': \"no-cache\",\r\n}\r\n\r\nr = requests.post(url, files=files, headers=headers)", "pub_date": "2018-10-23T10:07:21.924Z", "correctness": false, "question": 33, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 73, "fields": {"content": "I apologize for my misunderstanding in the beginning. The following code snippet gives the results you wish\r\n\r\nfrom sklearn.metrics import mean_squared_error\r\nimport pandas\r\nimport math\r\nimport numpy\r\n\r\ndf = pandas.DataFrame(numpy.random.randint(0, 100, size = (100, 2)), columns = ['labels','predictions']).sort_values(by = 'labels', ascending = True)\r\ndef rmse(df):\r\n    return numpy.sqrt(mean_squared_error(df['labels'], df['predictions']))\r\n\r\noutput = df.groupby(numpy.floor(numpy.array(df['labels'] / 7))).apply(rmse)\r\nrmse_df = pandas.DataFrame({'bout': [str(int(output.index[i] * 7)) + ' - ' + str(int(output.index[i + 1] * 7)) for i in range(output.shape[0] - 1)], 'rmse': output.values[:-1]})\r\nYou can change the 7s in my code for your variable step if you want to dynamically change the step size", "pub_date": "2018-10-23T10:08:38.913Z", "correctness": false, "question": 35, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 74, "fields": {"content": "If you know the coordinates of the corners of the rectangle, this is an fast, elegant solution that merely involves a couple of dot and scalar products: https://math.stackexchange.com/a/190373/178768", "pub_date": "2018-10-23T10:10:39.595Z", "correctness": false, "question": 37, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 75, "fields": {"content": "Would the rectangles be allowed to overlap? If so, would you want all the rectangles in a point, or just the one in the top layer?", "pub_date": "2018-10-23T10:10:51.251Z", "correctness": false, "question": 37, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 76, "fields": {"content": "Edit: After looking back, I'm using MonoGame and the OP is using Windows Forms. The following is for MonoGame.\r\n\r\nI've been messing this for a while now and have found a couple answers, just none of them actually worked. Here is a C# function that does exactly as OP describes, if not for OP then other people Googling like I was.\r\n\r\nIt was a headache to figure this out. A lot of the typical guesswork.\r\n\r\n    bool PointIsInRotatedRectangle(Vector2 P, Rectangle rect, float rotation)\r\n    {\r\n        Matrix rotMat = Matrix.CreateRotationZ(-rotation);\r\n        Vector2 Localpoint = P - (rect.Location).ToVector2();\r\n        Localpoint = Vector2.Transform(Localpoint, rotMat);\r\n        Localpoint += (rect.Location).ToVector2();\r\n\r\n        if (rect.Contains(Localpoint)) { return true; }\r\n        return false;\r\n    }\r\nAnd here it is in a single line of code. Probably faster to use.\r\n\r\n    bool PointIsInRotatedRectangle(Vector2 P, Rectangle rect, float rotation)\r\n    {\r\n        if (\r\n            rect.Contains(Vector2.Transform(P - (rect.Location).ToVector2(), Matrix.CreateRotationZ(-rotation)) + (rect.Location).ToVector2())\r\n            ) { return true; }\r\n        return false;\r\n    }", "pub_date": "2018-10-23T10:11:01.059Z", "correctness": false, "question": 37, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 77, "fields": {"content": "I know this was already answered but I had to do something similar a while ago. I created an extension method for the System.Windows.Point class that helped do exactly what Neil suggested:\r\n\r\n    public static double GetAngle(this Point pt)\r\n    {\r\n        return Math.Atan2(pt.X, -pt.Y) * 180 / Math.PI;\r\n    }\r\n\r\n    public static Point SetAngle(this Point pt, double angle)\r\n    {\r\n        var rads = angle * (Math.PI / 180);\r\n        var dist = Math.Sqrt(pt.X * pt.X + pt.Y * pt.Y);\r\n        pt.X = Math.Sin(rads) * dist;\r\n        pt.Y = -(Math.Cos(rads) * dist);\r\n        return pt;\r\n    }\r\nThis would allow me to work with the angles of points around 0, 0. So if you know the center of the rect that you are testing you would offset the point by the negative of this value (for example: pt.X -= 32; pt.Y -= 32) And then you would apply the negative rotation of the rectangle (as suggested by Neil: pt.SetAngle(-45);)...\r\n\r\nNow if the point is within 64, 64 you know you hit the rectangle. More specifically I was checking a pixel of a rotated image to make sure I hit a pixel of a specific color.", "pub_date": "2018-10-23T10:11:08.506Z", "correctness": false, "question": 37, "user": ["root"], "votes": -1}}, {"model": "stack.answer", "pk": 78, "fields": {"content": "You could keep a second, undisplayed image where you draw duplicates of the rectangles, each uniquely colored. When the user clicks on the picturebox, find the color of the corresponding pixel in the 2nd image, which will identify which rectangle was clicked.", "pub_date": "2018-10-23T10:11:14.255Z", "correctness": false, "question": 37, "user": ["root"], "votes": -1}}, {"model": "stack.answer", "pk": 79, "fields": {"content": "Is it possible to apply the same rotation applied to the rectangle to the point in reverse?\r\n\r\nFor example, Rectangle A is rotated 45 degrees clockwise from its origin (upper left corner), you would then just rotate point B around the same origin 45 degrees COUNTER clockwise, then check to see if it falls within Rectangle A pre-rotation", "pub_date": "2018-10-23T10:11:21.963Z", "correctness": true, "question": 37, "user": ["root"], "votes": 1}}, {"model": "stack.answer", "pk": 80, "fields": {"content": "This is how you get the angle between the vertical pink line and the black line starting at the pink line intersection:\r\n\r\nvar deg = 90 - Math.arctan((x2-x1) / (y2-y1));\r\nThe dimensions can be calculated with the help of the Pythagoras theorem:\r\n\r\nvar width = Math.sqrt((x2-x1)^2 / (y2-y1)^2));\r\nvar height = Math.sqrt((x1-x4)^2) / (y4-y1)^2));\r\nThe positional coordinates (left and top) are the averages of x1 and x3 and y1 and y3 respectively.\r\n\r\nvar left = Math.floor((x1 + x3) / 2);\r\nvar top = Math.floor((y1 + y3) / 2);\r\nYou want to use the negative-margin trick.\r\n\r\nvar marginLeft = -Math.ceil(width / 2);\r\nvar marginTop = -Math.ceil(height / 2);\r\nshareedit\r\nedited 15 hours ago\r\n\r\nJETM\r\n1,25241527\r\nanswered Oct 21 '12 at 22:56\r\n\r\nJ. K.\r\n6,93912933\r\n4\r\nJavascript trigonometry functions (such as Math.atan) return values in radians. There are Math.PI radians in 180\u00b0. Anyway, you're making life harder than it needs to be, the rotation of any side can be used, so the clockwise rotation angle (in radians) can be calulated from any coordinate pair on the same side, e.g.: Math.asin((x4-y1)/(y1-y4)). Note that where rotation exceeds 90\u00b0, further processing is required. \u2013 RobG Oct 22 '12 at 0:33", "pub_date": "2018-10-23T10:12:29.278Z", "correctness": false, "question": 38, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 81, "fields": {"content": "The center of the rectangle is right between two opposite corners:\r\n\r\ncx = (x1 + x3) / 2\r\ncy = (y1 + y3) / 2\r\nThe size of the rectangle is the distance between two points:\r\n\r\nw = sqrt(pow(x2-x1, 2) + pow(y2-y1, 2))\r\nh = sqrt(pow(x3-x2, 2) + pow(y3-y2, 2))\r\nThe corners of the gray rectangle can be calculated from the center and the size, for example the top left corner:\r\n\r\nx = cx - w / 2\r\ny = cy - h / 2\r\nThe angle is the arctangent of a side of the square:\r\n\r\na = arctan2(y4 - y1, x4 - x1)\r\n(I'm not sure exactly which angle it returns, or what angle you expect for that matter, so you get to test a bit.)", "pub_date": "2018-10-23T10:12:36.896Z", "correctness": false, "question": 38, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 82, "fields": {"content": "ou can use any coordinate pair on the same side to calculate the rotation angle. Note that mathematic angles normally assume 0 as long the +ve X axis and increase by rotating anti\u2013clockwise (so along the +ve Y axis is 90\u00b0, -ve X axis is 180\u00b0 and so on).\r\n\r\nAlso, javascript trigonometry functions return values in radians that must be converted to degrees before being used in a CSS transform.\r\n\r\nIf the shape is not rotated more than 90\u00b0, then life is fairly simple and you can use the tanget ratio of a right angle triangle:\r\n\r\ntan(angle) = length of opposite side / length of adjacent side\r\nFor the OP, the best corners to use are 1 and 4 so that rotation is kept in the first quadrant and clockwise (per the draft CSS3 spec). In javascript terms:\r\n\r\nvar rotationRadians = Math.atan((x1 - x4) / (y1 - y4));\r\nTo convert to degrees:\r\n\r\nvar RAD2DEG = 180 / Math.PI;\r\nvar rotationDegrees = rotationRadians * RAD2DEG;\r\nIf the rotation is more than 90\u00b0, you will need to adjust the angle. e.g. where the angle is greater than 90\u00b0 but less than 180\u00b0, you'll get a -ve result from the above and need to add 180\u00b0:\r\n\r\n  rotationDegrees += 180;\r\nAlso, if you are using page dimentions, y coordinates increase going down the page, which is the opposite of the normal mathetmatic sense so you need to reverse the sense of y1 - y4 in the above.\r\n\r\nEdit\r\nBased on the orientation of points in the OP, the following is a general function to return the center and clockwise rotation of the rectangle in degrees. That's all you should need, though you can rotate the corners to be \"level\" yourself if you wish. You can apply trigonometric functions to calculate new corners or just do some averages (similar to Ian's answer).\r\n\r\n/*  General case solution for a rectangle\r\n *\r\n *  Given coordinages of [x1, y1, x2, y2, x3, y3, x4, y4]\r\n *  where the corners are:\r\n *            top left    : x1, y1\r\n *            top right   : x2, y2\r\n *            bottom right: x3, y3\r\n *            bottom left : x4, y4\r\n *\r\n *  The centre is the average top left and bottom right coords:\r\n *  center: (x1 + x3) / 2 and (y1 + y3) / 2\r\n *\r\n *  Clockwise rotation: Math.atan((x1 - x4)/(y1 - y4)) with\r\n *  adjustment for the quadrant the angle is in.\r\n *\r\n *  Note that if using page coordinates, y is +ve down the page which\r\n *  is the reverse of the mathematic sense so y page coordinages\r\n *  should be multiplied by -1 before being given to the function.\r\n *  (e.g. a page y of 400 should be -400).\r\n */\r\nfunction getRotation(coords) {\r\n    // Get center as average of top left and bottom right\r\n    var center = [(coords[0] + coords[4]) / 2,\r\n                  (coords[1] + coords[5]) / 2];\r\n\r\n    // Get differences top left minus bottom left\r\n    var diffs = [coords[0] - coords[6], coords[1] - coords[7]];\r\n\r\n    // Get rotation in degrees\r\n    var rotation = Math.atan(diffs[0]/diffs[1]) * 180 / Math.PI;\r\n\r\n    // Adjust for 2nd & 3rd quadrants, i.e. diff y is -ve.\r\n    if (diffs[1] < 0) {\r\n        rotation += 180;\r\n\r\n    // Adjust for 4th quadrant\r\n    // i.e. diff x is -ve, diff y is +ve\r\n    } else if (diffs[0] < 0) {\r\n        rotation += 360;\r\n    }\r\n    // return array of [[centerX, centerY], rotation];\r\n    return [center, rotation];\r\n}\r\nshareedit\r\nedited Oct 22 '12 at 2:28\r\nanswered Oct 22 '12 at 1:01\r\n\r\nRobG\r\n95k1999143\r\nthanks a lot, I did not get the <90 angles, can you explain me? seem to be working fine, with some glitches, jsfiddle.net/Victornpb/nBKAP I also confused the matriz order, but I made the changes. acctually I'm tring to convert Collada to js+css, but seems a long road, I have no idea how to deal with Z coordinates. \u2013 Vitim.us Oct 22 '12 at 4:17\r\nThe point order and orientation in the fiddle is different to your post. It seems you are using cartesian coordinates, so where in the above I have coords[0] - coords[6] you need x3 - x4 and where I have coords[1] - coords[7] you need y3 - y4. \u2013 RobG Oct 22 '12 at 4:38 \r\nyeah Google sketchup uses cartesian. So instead of inverting axes I just swapped the top property to bottom to match things. And the rect points is actually in another order, is actually bottom-right-counter-cw [3,2][4,1] not top-left-cw [1,2][4,3] \u2013 Vitim.us Oct 22 '12 at 4:54", "pub_date": "2018-10-23T10:12:51.966Z", "correctness": true, "question": 38, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 83, "fields": {"content": "You can use length of dataframe to fix the columns elements\r\n\r\ndataFrame['3'] = np.ones(len(dataFrame))*8\r\nOut:\r\n\r\n0   1   2   3\r\n0   1.0 1.0 1.0 8.0\r\n1   2.0 2.0 2.0 8.0\r\n2   3.0 3.0 3.0 8.0\r\n3   NaN 4.0 4.0 8.0\r\n4   NaN 5.0 5.0 8.0\r\n5   NaN NaN 6.0 8.0\r\n6   NaN NaN 7.0 8.0", "pub_date": "2018-10-23T10:13:56.636Z", "correctness": false, "question": 39, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 84, "fields": {"content": "If you'd like to do it as you create the DataFrame, simply chain a call to assign:\r\n\r\npd.DataFrame(data).T.assign(**{'3': 8})\r\n     0    1    2  3\r\n0  1.0  1.0  1.0  8\r\n1  2.0  2.0  2.0  8\r\n2  3.0  3.0  3.0  8\r\n3  NaN  4.0  4.0  8\r\n4  NaN  5.0  5.0  8\r\n5  NaN  NaN  6.0  8\r\n6  NaN  NaN  7.0  8", "pub_date": "2018-10-23T10:14:02.888Z", "correctness": false, "question": 39, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 85, "fields": {"content": "You can do a def (read comments):\r\n\r\ndef f(df):\r\n   l=[8]*df[max(df,key=lambda x:df[x].count())].count()\r\n   df[3]=l+[np.nan]*(len(df)-len(l))\r\n   # the above two lines can be just `df[3] = another solution currently for this problem`\r\n   return df\r\ndataFrame = f(pandas.DataFrame(data).transpose())\r\nThen now:\r\n\r\nprint(dataFrame)\r\nReturns:\r\n\r\n     0    1    2  3\r\n0  1.0  1.0  1.0  8\r\n1  2.0  2.0  2.0  8\r\n2  3.0  3.0  3.0  8\r\n3  NaN  4.0  4.0  8\r\n4  NaN  5.0  5.0  8\r\n5  NaN  NaN  6.0  8\r\n6  NaN  NaN  7.0  8", "pub_date": "2018-10-23T10:14:10.236Z", "correctness": false, "question": 39, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 86, "fields": {"content": "If at you mean at the same time as running pd.DataFrame, the data has to be prepped before it is loaded to your frame.\r\n\r\ndata = [[1,2,3], [1,2,3,4,5], [1,2,3,4,5,6,7]]\r\n\r\nlongest = max(len(i) for i in data)\r\ndummy = [8 for i in range(longest)] #dummy data filled with 8\r\ndata.append(dummy)\r\n\r\ndataFrame = pd.DataFrame(data).transpose()\r\nThe example above gets the longest element in your list and creates a dummy to be added onto it before creating your dataframe.", "pub_date": "2018-10-23T10:14:18.223Z", "correctness": false, "question": 39, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 87, "fields": {"content": "It is not entirely clear what you mean by at the same time, but the following would work:\r\n\r\nimport pandas as pd\r\n\r\ndata = [[1,2,3], [1,2,3,4,5], [1,2,3,4,5,6,7]]\r\n# get the longest list in data\r\ndata.append([8] * max(map(len, data)))\r\npd.DataFrame(data).transpose()\r\nyielding\r\n\r\n     0    1    2    3\r\n0  1.0  1.0  1.0  8.0\r\n1  2.0  2.0  2.0  8.0\r\n2  3.0  3.0  3.0  8.0\r\n3  NaN  4.0  4.0  8.0\r\n4  NaN  5.0  5.0  8.0\r\n5  NaN  NaN  6.0  8.0\r\n6  NaN  NaN  7.0  8.0", "pub_date": "2018-10-23T10:14:24.566Z", "correctness": false, "question": 39, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 88, "fields": {"content": "You can append to a list which then immediately feeds the pd.DataFrame constructor:\r\n\r\nimport pandas as pd\r\n\r\ndata = [[1,2,3], [1,2,3,4,5], [1,2,3,4,5,6,7]]\r\n\r\ndf = pd.DataFrame(data + [[8]*max(map(len, data))]).transpose()\r\n\r\nprint(df)\r\n\r\n     0    1    2    3\r\n0  1.0  1.0  1.0  8.0\r\n1  2.0  2.0  2.0  8.0\r\n2  3.0  3.0  3.0  8.0\r\n3  NaN  4.0  4.0  8.0\r\n4  NaN  5.0  5.0  8.0\r\n5  NaN  NaN  6.0  8.0\r\n6  NaN  NaN  7.0  8.0\r\nBut this is inefficient. Pandas uses NumPy to hold underlying series and setting a series to a constant value is trivial and efficient; you can simply use:\r\n\r\ndf[3] = 8", "pub_date": "2018-10-23T10:14:31.277Z", "correctness": false, "question": 39, "user": ["root"], "votes": 0}}, {"model": "stack.answer", "pk": 89, "fields": {"content": "Using groupby + transform\r\n\r\n#df[['startdate','enddate']]=df[['startdate','enddate']].apply(pd.to_datetime)\r\ng=df.groupby(['cpf' ,'day'])\r\ndf['DIFF']=g.enddate.transform('last')-g.startdate.transform('first')", "pub_date": "2018-10-23T10:15:48.613Z", "correctness": true, "question": 41, "user": ["root"], "votes": 1}}, {"model": "stack.question", "pk": 1, "fields": {"header": "Why is it faster to process a sorted array than an unsorted array?", "content": "22029down votefavorite10099Here is a piece of C++ code that seems very peculiar. For some strange reason, sorting the data miraculously makes the code almost six times faster.#include <algorithm>#include <ctime>#include <iostream>int main(){    // Generate data    const unsigned arraySize = 32768;    int data[arraySize];    for (unsigned c = 0; c < arraySize; ++c)        data[c] = std::rand() % 256;    // !!! With this, the next loop runs faster    std::sort(data, data + arraySize);    // Test    clock_t start = clock();    long long sum = 0;    for (unsigned i = 0; i < 100000; ++i)    {        // Primary loop        for (unsigned c = 0; c < arraySize; ++c)        {            if (data[c] >= 128)                sum += data[c];        }    }    double elapsedTime = static_cast<double>(clock() - start) / CLOCKS_PER_SEC;    std::cout << elapsedTime << std::endl;    std::cout << \"sum = \" << sum << std::endl;}Without std::sort(data, data + arraySize);, the code runs in 11.54 seconds.With the sorted data, the code runs in 1.93 seconds.Initially, I thought this might be just a language or compiler anomaly. So I tried it in Java.import java.util.Arrays;import java.util.Random;public class Main{    public static void main(String[] args)    {        // Generate data        int arraySize = 32768;        int data[] = new int[arraySize];        Random rnd = new Random(0);        for (int c = 0; c < arraySize; ++c)            data[c] = rnd.nextInt() % 256;        // !!! With this, the next loop runs faster        Arrays.sort(data);        // Test        long start = System.nanoTime();        long sum = 0;        for (int i = 0; i < 100000; ++i)        {            // Primary loop            for (int c = 0; c < arraySize; ++c)            {                if (data[c] >= 128)                    sum += data[c];            }        }        System.out.println((System.nanoTime() - start) / 1000000000.0);        System.out.println(\"sum = \" + sum);    }}With a somewhat similar but less extreme result.My first thought was that sorting brings the data into the cache, but then I thought how silly that is because the array was just generated.What is going on?Why is it faster to process a sorted array than an unsorted array?The code is summing up some independent terms, and the order should not matter.", "pub_date": "2018-10-23T09:29:42.944Z", "user": ["u5"], "votes": 2, "tag": [1, 2, 3]}}, {"model": "stack.question", "pk": 2, "fields": {"header": "Convert DateTime to String PHP", "content": "I have already researched a lot of site on how can I convert PHP DateTime object to String. I always see \"String to DateTime\" and not \"DateTime to String\"PHP DateTime can be echoed, but what i want to process my DateTime with PHP string functions.My question is how can I make PHP dateTime Object to a string starting from this kind of code:$dts = new DateTime(); //this returns the current date timeecho strlen($dts);", "pub_date": "2018-10-23T09:34:08.462Z", "user": ["u4"], "votes": 0, "tag": [4, 5]}}, {"model": "stack.question", "pk": 3, "fields": {"header": "Linking in react native can open just one app", "content": "UPDATE 1I removed return from code and now links work on IOS. But on android I can't open any app. Any idea?I am trying to open different apps from my app.return Linking.openURL(\u201ctwitter://\u201c);return Linking.openURL(\u201cinstagram://\u201c);But it doesn\u2019t work. I configured IOS by documentation. On android doesn\u2019t work too. While...return Linking.openURL(\u201ctripadvisor://\u201c);Work just fine. Any idea why I can\u2019t open other apps.This is code that I am using (open app if installed or open store with it but sometimes even store doesn't open) what I did wrong:let appUrl = \"instagram://\";Linking.canOpenURL(appUrl).then(supported => {            if (!supported) {              Alert.alert(\"\",                \"\",                [                  {text: \"go to store\", onPress: this.openStorePress},                  {text: \"cancel\", onPress: () => { }, style: 'cancel'},                ],                { cancelable: false }              );            } else {              return Linking.openURL(appUrl);            }        }).catch(err => {            console.error(err);        });", "pub_date": "2018-10-23T09:36:45.928Z", "user": ["user54"], "votes": 0, "tag": [6]}}, {"model": "stack.question", "pk": 4, "fields": {"header": "Python 3.X pulling too many ip addresses when trying to read file", "content": "I have a scan report from Nmap. I'm trying to get the information that only pertains to the certain IP address. I'm trying pull the IP address for this part of the code I will work on the next piece later. I think it has something to do with the \\n character at the end of the IP address. I need the code to say I want this IP address and this IP address alone. Any help is greatly appreciated.\r\n\r\n#Python3.X \r\ntarget_ip = \"10.10.100.1\"\r\n\r\n\r\nfhand = open('ScanTest.txt','r')\r\nfor line in fhand:\r\n    line = line.rstrip()\r\n    if line.startswith('Nmap scan report for')and (target_ip):\r\n        print(line)\r\nMy results end up being\r\n\r\nNmap scan report for 10.10.100.1\r\nNmap scan report for 10.10.100.2\r\nNmap scan report for 10.10.100.100\r\nNmap scan report for 10.10.100.101\r\nNmap scan report for 10.10.100.103\r\nNmap scan report for 10.10.100.102", "pub_date": "2018-10-23T09:37:16.553Z", "user": ["root"], "votes": 0, "tag": [7, 8, 9]}}, {"model": "stack.question", "pk": 5, "fields": {"header": "SQL: SELECT where one of many columns contains 'x' and result is not \u201cNULL\u201d", "content": "Basically, I have a database table like this:Example DB tableAny or several of columns A-G might match my search query. If that is the case, I want to query VALUE from that row. I need VALUE not to equal NULL though, so if that's the case, it should keep looking. If my query were abc, I'd want to obtain correct.Below is my current code, using a database named db with a table table.cur=db.cursor()data=\"123\"fields_to_check=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"]for field in fields_to_check:    \"SELECT Value FROM table WHERE {}='{}'\".format(field,data)    query=cur.fetchone()    if query and query !=\"NULL\":        breakdb.close()", "pub_date": "2018-10-23T09:38:38.890Z", "user": ["u3"], "votes": 0, "tag": [8, 10]}}, {"model": "stack.question", "pk": 6, "fields": {"header": "Get dictionary with key/value in a list of dictionaries", "content": "I have a list of dictionaries that looks like this:\r\n\r\n[\r\n    {\r\n        \"name\": \"hello\",\r\n        \"value\": \"world\"\r\n    },\r\n    {\r\n        \"name\": \"foo\",\r\n        \"value\": \"bar\"\r\n    }\r\n]\r\nWhat's the pythonic way of fetching the dictionary where name = \"foo\" from a list of dictionaries?", "pub_date": "2018-10-23T09:39:42.057Z", "user": ["root"], "votes": 0, "tag": [8]}}, {"model": "stack.question", "pk": 7, "fields": {"header": "Asking user how many values to update and update that many values in dictionary by using values from another list of values Ask Question", "content": "Given one dictionary dictionary and a list letter_frequency:\r\n\r\nletter_frequency=[\"e\", \"t\", \"a\", \"o\", \"i\", \"n\", \"s\", \"r\", \"h\", \"l\", \"d\", \"c\", \"u\", \"m\", \"f\", \"p\", \"g\", \"w\", \"y\", \"b\", \"v\", \"k\", \"x\", \"j\", \"q\",\"z\"]\r\ndictionary={'s': 28, 'o': 24, 'c': 20, 'w': 20, 'g': 17, 'm': 17, 't': 17, 'k': 14, 'e': 11, 'n': 10, 'f': 8, 'd': 7, 'y': 7, 'i': 6, 'l': 6, 'q': 6, 'j': 5, 'a': 2, 'r': 2, 'u': 2, 'v': 2, 'z': 1, 'b': 0, 'h': 0, 'p': 0, 'x': 0}\r\nAsk user to enter how many values we have update? Like this:\r\n\r\nenter how  many values we have update?\r\n\r\nIf the use enters 5, first 5 values in the dictionay will be replace with the corresponding values in the list letter_frequency i.e. key-value pair for first 5 changes to\r\n's':'e', 'o':'t','c': 'a', 'w': 'o', 'g': 'i' and rest all key-value pair remains same. So the ouput should be:\r\n\r\n{'s': 'e', 'o': 't', 'c': 'a', 'w': 'o', 'g': 'i', 'm': 'm', 't': 't', 'k': 'k', 'e': 'e', 'n': 'n', 'f': 'f', 'd': 'd', 'y': 'y', 'i': 'i', 'l': 'l', 'q': 'q', 'j': 'j', 'a': 'a', 'r': 'r', 'u': 'u', 'v': 'v', 'z': 'z', 'b': 'b', 'h': 'h', 'p': 'p', 'x': 'x'}", "pub_date": "2018-10-23T09:40:34.926Z", "user": ["root"], "votes": 0, "tag": [7, 8, 11]}}, {"model": "stack.question", "pk": 8, "fields": {"header": "str.startswith() not working as I intended", "content": "I can't see why this won't work. I am performing lstrip() on the string being passed to the function, and trying to see if it starts with \"\"\". For some reason, it gets caught in an infinite loop\r\n\r\ndef find_comment(infile, line):\r\n\r\n    line_t = line.lstrip()\r\n    if not line_t.startswith('\"\"\"') and not line_t.startswith('#'):\r\n        print (line, end = '')\r\n        return line\r\n\r\n    elif line.lstrip().startswith('\"\"\"'):\r\n            while True:\r\n                if line.rstrip().endswith('\"\"\"'):\r\n                    line = infile.readline()\r\n                    find_comment(infile, line)\r\n                else:\r\n                    line = infile.readline()\r\n    else:\r\n        line = infile.readline()\r\n        find_comment(infile, line)\r\nAnd my output:\r\n\r\nEnter the file name: test.txt\r\nimport re\r\ndef count_loc(infile):\r\nHere is the top of the file i am reading in for reference:\r\n\r\n    import re\r\n\r\n    def count_loc(infile):\r\n        \"\"\" Receives a file and then returns the amount\r\n            of actual lines of code by not counting commented\r\n            or blank lines \"\"\"\r\n\r\n        loc = 0\r\n        func_records = {}\r\n        for line in infile:\r\n        (...)", "pub_date": "2018-10-23T09:41:22.156Z", "user": ["root"], "votes": 0, "tag": [7, 8, 12]}}, {"model": "stack.question", "pk": 9, "fields": {"header": "Python 3.0 and language evolution", "content": "Python 3.0 breaks backwards compatibility with previous versions and splits the language into two paths (at least temporarily). Do you know of any other language that went through such a major design phase while in maturity?\r\n\r\nAlso, do you believe that this is how programming languages should evolve or is the price to pay simply too high?", "pub_date": "2018-10-23T09:42:39.523Z", "user": ["root"], "votes": 0, "tag": [7, 8, 13]}}, {"model": "stack.question", "pk": 10, "fields": {"header": "Python 3 porting workflow?", "content": "I have a small project I want to try porting to Python 3 - how do I go about this?I have made made the code run without warnings using python2.6 -3 (mostly removing .has_key() calls), but I am not sure of the best way to use the 2to3 tool.Use the 2to3 tool to convert this source code to 3.0 syntax. Do not manually edit the output!Running 2to3 something.py outputs a diff, which isn't useful on it's own. Using the --write flag overwrites something.py and creates a backup.. It seems like I have to do..2to3 something.pypython3.0 something.pymv something.py.bak something.pyvim something.py# repeat..which is a bit round-a-bout - ideally I could do something like..mv something.py py2.6_something.py # once2to3 py2.6_something.py --write-file something.pyvim py2.6_something.py# repeat", "pub_date": "2018-10-23T09:44:59.557Z", "user": ["u2"], "votes": 0, "tag": [7, 8, 14]}}, {"model": "stack.question", "pk": 11, "fields": {"header": "Will everything in the standard library treat strings as unicode in Python 3.0?", "content": "I'm a little confused about how the standard library will behave now that Python (from 3.0) is unicode-based. Will modules such as CGI and urllib use unicode strings or will they use the new 'bytes' type and just provide encoded data?", "pub_date": "2018-10-23T09:46:24.563Z", "user": ["root"], "votes": 1, "tag": [7, 8, 15]}}, {"model": "stack.question", "pk": 12, "fields": {"header": "Python 3 and open source: Are there any good projects?", "content": "I've been studying Python 3 recently and I have come across a conundrum: I want to expand my abilities by working on an open source project, but I seem to have trouble finding any specifically for Python 3.\r\n\r\nI know that this question has been asked before:\r\nSuch as here,\r\nAnd here,\r\nUnfortunately these all seem to be using Python <= 2.6 and I want to use >= 3.0\r\n\r\nThis leads me to another question: Python 3.0 has been out for almost a year, yet most of the examples and 90% of the projects are for <= 2.6. I also know that the MySQL library is not in a Python 3 compatible state. Does this mean that I'd actually better off learning Python 2.x and assume the incompatible 3.0 will die?", "pub_date": "2018-10-23T09:48:06.889Z", "user": ["root"], "votes": 0, "tag": [7, 8, 16]}}, {"model": "stack.question", "pk": 13, "fields": {"header": "Converting 2.5 byte comparisons to 3", "content": "I'm trying to convert a 2.5 program to 3.\r\n\r\nIs there a way in python 3 to change a byte string, such as b'\\x01\\x02' to a python 2.5 style string, such as '\\x01\\x02', so that string and byte-by-byte comparisons work similarly to 2.5? I'm reading the string from a binary file.\r\n\r\nI have a 2.5 program that reads bytes from a file, then compares or processes each byte or combination of bytes with specified constants. To run the program under 3, I'd like to avoid changing all my constants to bytes and byte strings ('\\x01' to b'\\x01'), then dealing with issues in 3 such as:\r\n\r\na = b'\\x01'\r\nb = b'\\x02'\r\nresults in\r\n\r\n(a+b)[0] != a\r\neven though similar operation work in 2.5. I have to do (a+b)[0] == ord(a), while a+b == b'\\x01\\x02' works fine. (By the way, what do I do to (a+b)[0] so it equals a?)\r\n\r\nUnpacking structures is also an issue.\r\n\r\nAm I missing something simple?", "pub_date": "2018-10-23T09:48:56.840Z", "user": ["root"], "votes": 0, "tag": [7, 8]}}, {"model": "stack.question", "pk": 14, "fields": {"header": "String formatting", "content": "I have a list filter = ['a', 'b', 'c']. I need to frame the following string out of the list \"item -a item -b item -c\". Which is the most efficient way to do this? Usually the list filter contains 100 to 200 items and each would be of length 100 - 150. Wouldn't that lead to overflow? And what is the maximum length of the string supported?", "pub_date": "2018-10-23T09:49:54.065Z", "user": ["root"], "votes": 0, "tag": []}}, {"model": "stack.question", "pk": 15, "fields": {"header": "python 3.1 with pydev", "content": "I am now moving to eclipse for my python development. I have pydev installed but it is showing grammar support up to python version 3.0. My question is can I use python 3.1 with 3.0 grammar? Has the grammar changed from version 3.0 to 3.1?\r\n\r\nI am using eclipse 3.4.2 and pydev 1.4.7", "pub_date": "2018-10-23T09:50:38.311Z", "user": ["root"], "votes": 0, "tag": [7, 8, 17]}}, {"model": "stack.question", "pk": 16, "fields": {"header": "Python3 Http Web Server: virtual hosts", "content": "I am writing an rather simple http web server in python3. The web server needs to be simple - only basic reading from config files, etc. I am using only standard libraries and for now it works rather ok.\r\n\r\nThere is only one requirement for this project, which I can't implement on my own - virtual hosts. I need to have at least two virtual hosts, defined in config files. The problem is, that I can't find a way how can I implement them in python. Does anyone have any guides, articles, maybe some simple implementation how can this be done?\r\n\r\nI would be grateful for any help.", "pub_date": "2018-10-23T09:51:24.702Z", "user": ["root"], "votes": 0, "tag": [7, 8, 18]}}, {"model": "stack.question", "pk": 17, "fields": {"header": "Python 3.X pulling too many ip addresses when trying to read file", "content": "I have a scan report from Nmap. I'm trying to get the information that only pertains to the certain IP address. I'm trying pull the IP address for this part of the code I will work on the next piece later. I think it has something to do with the \\n character at the end of the IP address. I need the code to say I want this IP address and this IP address alone. Any help is greatly appreciated.#Python3.X target_ip = \"10.10.100.1\"fhand = open('ScanTest.txt','r')for line in fhand:    line = line.rstrip()    if line.startswith('Nmap scan report for')and (target_ip):        print(line)My results end up beingNmap scan report for 10.10.100.1Nmap scan report for 10.10.100.2Nmap scan report for 10.10.100.100Nmap scan report for 10.10.100.101Nmap scan report for 10.10.100.103Nmap scan report for 10.10.100.102", "pub_date": "2018-10-23T09:52:28.050Z", "user": ["u4"], "votes": 0, "tag": [7, 8, 9]}}, {"model": "stack.question", "pk": 18, "fields": {"header": "Python 3.X pulling too many ip addresses when trying to read file", "content": "I have a scan report from Nmap. I'm trying to get the information that only pertains to the certain IP address. I'm trying pull the IP address for this part of the code I will work on the next piece later. I think it has something to do with the \\n character at the end of the IP address. I need the code to say I want this IP address and this IP address alone. Any help is greatly appreciated.#Python3.X target_ip = \"10.10.100.1\"fhand = open('ScanTest.txt','r')for line in fhand:    line = line.rstrip()    if line.startswith('Nmap scan report for')and (target_ip):        print(line)My results end up beingNmap scan report for 10.10.100.1Nmap scan report for 10.10.100.2Nmap scan report for 10.10.100.100Nmap scan report for 10.10.100.101Nmap scan report for 10.10.100.103Nmap scan report for 10.10.100.102", "pub_date": "2018-10-23T09:53:09.472Z", "user": ["root"], "votes": 5, "tag": [7, 8, 9]}}, {"model": "stack.question", "pk": 19, "fields": {"header": "Python datatype that includes uncertainty/error bars?", "content": "Is there a python datatype that includes numerical error bars?For example,: a = 3.00 \u00b1 0.100: b = 4.00 \u00b1 0.100: b + a>> 7.00 \u00b1 0.141Where \u221a(0.1^2 + 0.1^2) = 0.141I figured since imaginary numbers already exist in a form something like this a= 3 + j4, maybe there is a module that handles error analysis for you as well. (I suppose it's complicated by the fact that the + & - uncertainties need not be equal.)", "pub_date": "2018-10-23T09:54:06.796Z", "user": ["root"], "votes": 3, "tag": [7, 19]}}, {"model": "stack.question", "pk": 20, "fields": {"header": "How do I give twisted server an ip address?", "content": "I am trying to write a simple client/server (where client and server are not the same machine) and cannot figure out how to give twisted an ip address.\r\n\r\nfrom twisted.internet import protocol, reactor, endpoints\r\nfrom twisted.protocols import basic\r\n\r\nclass FingerProtocol(basic.LineReceiver):\r\n    def lineReceived(self, user):\r\n        self.transport.write(self.factory.getUser(user) + b\"\\r\\n\")\r\n        self.transport.loseConnection()\r\n\r\nclass FingerFactory(protocol.ServerFactory):\r\n    protocol = FingerProtocol\r\n\r\n    def __init__(self, users):\r\n        self.users = users\r\n\r\n    def getUser(self, user):\r\n        return self.users.get(user, b\"No such user\")\r\n\r\nfingerEndpoint = endpoints.serverFromString(reactor, (\"192.168.1.7\", \"tcp:1079\"))\r\nfingerEndpoint.listen((FingerFactory({ b'moshez' : b'Happy and well'})))\r\nreactor.run()\r\nerror:\r\n\r\nTraceback (most recent call last):\r\n  File \"sensors/twistedTest.003.py\", line 20, in <module>\r\n    fingerEndpoint = endpoints.serverFromString(reactor, (\"192.168.1.7\", \"tcp:1079\"))\r\n  File \"/usr/local/lib/python3.5/dist-packages/twisted/internet/endpoints.py\", line 1724, in serverFromString\r\n    nameOrPlugin, args, kw = _parseServer(description, None)\r\n  File \"/usr/local/lib/python3.5/dist-packages/twisted/internet/endpoints.py\", line 1635, in _parseServer\r\n    args, kw = _parse(description)\r\n  File \"/usr/local/lib/python3.5/dist-packages/twisted/internet/endpoints.py\", line 1596, in _parse\r\n    for (type, value) in _tokenize(description):\r\n  File \"/usr/local/lib/python3.5/dist-packages/twisted/internet/endpoints.py\", line 1570, in _tokenize\r\n    current += n\r\nTypeError: can't concat bytes to tuple\r\nHow do I give twisted/reactor an ip address?", "pub_date": "2018-10-23T09:54:44.457Z", "user": ["root"], "votes": -1, "tag": [7, 8, 20]}}, {"model": "stack.question", "pk": 21, "fields": {"header": "python/pandas: convert month int to month name", "content": "Most of the info I found was not in python>pandas>dataframe hence the question.\r\n\r\nI want to transform an integer between 1 and 12 into an abbrieviated month name.\r\n\r\nI have a df which looks like:\r\n\r\n   client Month\r\n1  sss    02\r\n2  yyy    12\r\n3  www    06\r\nI want the df to look like this:\r\n\r\n   client Month\r\n1  sss    Feb\r\n2  yyy    Dec\r\n3  www    Jun", "pub_date": "2018-10-23T09:56:06.990Z", "user": ["root"], "votes": 1, "tag": [7, 21]}}, {"model": "stack.question", "pk": 22, "fields": {"header": "Pandas writing dataframe to CSV file", "content": "I have a dataframe in pandas which I would like to write to a CSV file. I am doing this using:\r\n\r\ndf.to_csv('out.csv')\r\nAnd getting the error:\r\n\r\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\u03b1' in position 20: ordinal not in range(128)\r\nIs there any way to get around this easily (i.e. I have unicode characters in my data frame)? And is there a way to write to a tab delimited file instead of a CSV using e.g. a 'to-tab' method (that I dont think exists)?", "pub_date": "2018-10-23T09:57:58.546Z", "user": ["root"], "votes": 1, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 23, "fields": {"header": "Print dataframe column", "content": "File1 only has 1 column: name/ File2 has 3 columns: name, num1, num2\r\n\r\nfrom fuzzywuzzy import fuzz\r\nfrom fuzzywuzzy import process\r\nimport pandas as pd\r\n\r\ndata1 = pd.read_csv('file1.csv')\r\ndata_list1 = data_to_match['Name1']\r\n\r\ndata2 = pd.read_csv('file2.csv')\r\ndata_list2  = data_master['Name2']\r\n\r\n\r\nrecode = {}\r\nfor name in data_list1:\r\n    best_match = process.extractOne(name, data_list2)\r\n    if best_match[1] < 100:\r\n        print(name, best_match, data_list2.num1, data_list2.num2)\r\n    recode[name] = best_match[0]\r\nHow do I print out the num1, num2 in the print statement?", "pub_date": "2018-10-23T09:59:30.658Z", "user": ["root"], "votes": 1, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 24, "fields": {"header": "Handle empty result with read_sql chunked", "content": "I am still learning Python, I need to handle a case when a sql query doesn't provide any rows, with a pandas read_sql function with chunksize param.Here is the current line :df = pd.concat([x for x in pd.read_sql(SQL_request,self.connection, chunksize=50000)], ignore_index=True)When the query returns zero rows I get this error :  File \"[....]\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\", line 239, in __init__    raise ValueError('No objects to concatenate')ValueError: No objects to concatenateWhat is the best way to handle this ? I need to return an empty dataframe even if there is no rows (the columns must be there). I need to keep the chunking, it really helps not using too much memory.I thought about running a first query without chunking and check if there is any rows, and then run a second chunked query. But I feel it is a very bad and inefficient idea.", "pub_date": "2018-10-23T09:59:47.503Z", "user": ["user54"], "votes": 0, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 25, "fields": {"header": "Drop rows with sub-string value given", "content": "Drop rowsfrom dataframe given the subsstring is present in particular col's row.\r\n\r\ndf:\r\n\r\nParent  Child   score\r\n1stqw   Whoert      0.305125\r\ntWowe   Tasert      0.308132\r\nWorert  Picert      0.315145\r\nsubstrings = [Wor,Tas]\r\n\r\nDrop rows having the substrings.\r\n\r\nUpdated df:\r\n\r\n Parent Child   score\r\n1stqw   Whoert      0.305125\r\nthanks!!", "pub_date": "2018-10-23T10:00:30.411Z", "user": ["root"], "votes": 0, "tag": [7, 8, 21]}}, {"model": "stack.question", "pk": 26, "fields": {"header": "calculate root-mean-squared-error of regression in bouts", "content": "lets assume that I get the following pandas dataframe for my regression analysis.\r\n\r\nimport pandas\r\nimport math\r\nimport numpy\r\n\r\ndf = pandas.DataFrame(numpy.random.randint(0,100,size=(100, 2)), columns=['labels','predictions'])\r\nI would like now to calculate the RMSE as\r\n\r\nmath.sqrt(numpy.mean((df[\"predictions\"] - df[\"lables\"]) ** 2)) \r\nfor values of the labels in interval of 7\r\n\r\nHereby a very ugly code that does the job...it would be nice if you help me to pythonize it...\r\n\r\n# define step\r\nstep = 7\r\n# initialize counter\r\nidx = 0\r\n# initialize empty dataframe\r\nrmse = pandas.DataFrame(columns=['bout' , 'rmse'],index=range(0,len(range(int(df['labels'].min())+step,int(df['labels'].max()),step))))\r\n\r\n# start loop to calculate rmse every 7 units\r\nfor i in range(int(df['labels'].min())+step,int(df['labels'].max()),step):\r\n\r\n    # select values in interval\r\n    df_bout = df[(df['labels']>=i-step) & (df['labels']<i)]\r\n\r\n    # calculate rmse in interval\r\n    rmse.loc[idx] = [str(i-step)+'-'+str(i),math.sqrt(numpy.mean((df_bout.predictions - df_bout.labels) ** 2))]\r\n\r\n    # increment counter\r\n    idx = idx + 1", "pub_date": "2018-10-23T10:01:46.126Z", "user": ["root"], "votes": 0, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 27, "fields": {"header": "Compare 2 columns in different dataframes with a primary key condition without merge", "content": "I have 2 different dataframe Ex:\r\n\r\nDf1:\r\n\r\nUser_id    User_name     User_phn\r\n1          Alex          1234123\r\n2          Danny         4234123\r\n3          Bryan         5234123\r\nDf2:\r\n\r\nUser_id    User_name     User_phn\r\n1          Alex          3234123\r\n2          Chris         4234123\r\n3          Bryan         5234123\r\n4          Bexy          6234123\r\nuser_id is the primary key in both the tables and I need to compare both the dataframes using the user_id as a condition and result me with values which are having matching and mismatch values without merging the dataframes into a new dataframe.\r\n\r\nResult:\r\n\r\nUser_id    User_name     User_phn\r\n1          Alex          Mismatch\r\n2          Mismatch      4234123\r\n3          Bryan         5234123\r\n4          Mismatch      Mismatch", "pub_date": "2018-10-23T10:02:26.448Z", "user": ["root"], "votes": 0, "tag": [7, 8, 21]}}, {"model": "stack.question", "pk": 28, "fields": {"header": "Pandas python: getting one value from a DataFrame", "content": "I implemented a function that goes to the first occurence of a valued in a panda dataframe but I feel the implementation is kindda ugly. Would you have a nicer way to implement it??[mots] is an array of strings# Sans doutes la pire impl\u00e9mentation au monde...def find_singular_value(self, mots):    bool_table = self.document.isin(mots)    for i in range(bool_table.shape[0]):        for j in range(bool_table.shape[1]):            boolean = bool_table.iloc[i][j]            if boolean:                return self.document.iloc[i][j + 1]", "pub_date": "2018-10-23T10:03:45.986Z", "user": ["test_user"], "votes": 0, "tag": [7, 8, 21]}}, {"model": "stack.question", "pk": 29, "fields": {"header": "Convert Array to DenseVector in Spark DataFrame using Java", "content": "I am running Spark 2.3. I want to convert the column features in the following DataFrame from ArrayType to a DenseVector. I am using Spark in Java.+---+--------------------+| id|            features|+---+--------------------+|  0|[4.191401, -1.793...|| 10|[-0.5674514, -1.3...|| 20|[0.735613, -0.026...|| 30|[-0.030161237, 0....|| 40|[-0.038345724, -0...|+---+--------------------+root |-- id: integer (nullable = false) |-- features: array (nullable = true) |    |-- element: float (containsNull = false)I have written the following UDF but it doesn't seem to be working:private static UDF1 toVector = new UDF1<Float[], Vector>() {    private static final long serialVersionUID = 1L;    @Override    public Vector call(Float[] t1) throws Exception {        double[] DoubleArray = new double[t1.length];        for (int i = 0 ; i < t1.length; i++)        {            DoubleArray[i] = (double) t1[i];        }       Vector vector = (org.apache.spark.mllib.linalg.Vector) Vectors.dense(DoubleArray);    return vector;    }I wish to extract the following features as a vector so that I can perform clustering on it.I am also registering the UDF and then proceeding on to call it.spark.udf().register(\"toVector\", (UserDefinedAggregateFunction) toVector);df3=df3.withColumn(\"featuresnew\",callUDF(\"toVector\",df3.col(\"feautres\")));df3.show();  On running this snippet I am facing the following error:ReadProcessData$1 cannot be cast to org.apache.spark.sql.expressions. UserDefinedAggregateFunction", "pub_date": "2018-10-23T10:04:27.253Z", "user": ["u3"], "votes": 1, "tag": [1, 21, 23]}}, {"model": "stack.question", "pk": 30, "fields": {"header": "DataFrame constructor not properly called", "content": "I am trying to create a dataframe with Python, which raise the Error in the qustion title\r\n\r\n  # pre processing to get G-Test score\r\n    def G_test(tokens, types):\r\n        tokens_cnt = tokens.value_counts().astype(float)\r\n        types_cnt = types.value_counts().astype(float)\r\n        total_cnt = float(sum(tokens_cnt))\r\n\r\n        # calculate each token counts\r\n        token_cnt_table = collections.defaultdict(lambda : collections.Counter())\r\n        for _tokens, _types in zip(tokens.values, types.values):\r\n            token_cnt_table[_tokens][_types] += 1\r\n\r\n\r\n tc_dataframe = pd.DataFrame(token_cnt_table.values(), index=token_cnt_table.keys())\r\n\r\n        tc_dataframe.fillna(0, inplace=True)\r\n        for column in tc_dataframe.columns.tolist():\r\n            tc_dataframe[column+'_exp'] = (tokens_cnt / total_cnt) * types_cnt[column]\r\n            c_dataframe[column+'_GTest'] = [G_test_score(tkn_count, exp) for tkn_count, exp in zip(tc_dataframe[column], tc_dataframe[column+'_exp'])]\r\n            return tc_dataframe", "pub_date": "2018-10-23T10:04:55.861Z", "user": ["root"], "votes": 0, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 31, "fields": {"header": "Data frame splitting", "content": "I'm having problems splitting a dataframeEx of data in data frame:27/09/2017;2335W;0;;1\"88485170\"I'm trying to split if withdata.split(\";\")But I get AttributeError: 'DataFrame' object has no attribute 'split'Any Idea of what I need to do in order to separate it? The first part is data, the second is time (I also need to erase the W) the 3 part is a number and the last is also a numberCode:import pandas as pdfrom datetime import timedelta,time,datetimedata=pd.read_excel(\"Book1.xlsx\")data1= data.split(\";\",n=4,expand =True)AttributeError: 'Data Frame' object has no attribute 'split'", "pub_date": "2018-10-23T10:05:24.898Z", "user": ["u4"], "votes": 1, "tag": [5, 8, 21]}}, {"model": "stack.question", "pk": 32, "fields": {"header": "Python, Pandas write to dataframe, lxml.etree.SerialisationError: IO_WRITE", "content": "Code to pick the wanted lines from a dataframe. The original data is in Excel format and I put it in dataframe here.\r\n\r\nI want to pick all the rows of \u201cTest Date\u201d fall in \u201c201506\u201d and \u201c201508\u201d, and write them to an Excel file. The lines are working fine.\r\n\r\nimport pandas as pd\r\n\r\ndata_short = {'Contract_type' : [\"Other\", \"Other\", \"Type-I\", \"Type-I\", \"Type-I\", \"Type-II\", \"Type-II\", \"Type-III\", \"Type-III\", \"Part-time\"],\r\n'Test Date': [\"20150816\", \"20150601\", \"20150204\", \"20150609\", \"20150204\", \"20150806\", \"20150201\", \"20150615\", \"20150822\", \"20150236\" ],\r\n'Test_time' : [\"16:26\", \"07:39\", \"18:48\", \"22:32\", \"03:54\", \"03:30\", \"04:00\", \"22:02\", \"13:43\", \"10:29\"],\r\n}\r\n\r\ndf = pd.DataFrame(data_short)\r\n\r\ndata_201508 = df[df['Test Date'].astype(str).str.startswith('201508')]\r\ndata_201506 = df[df['Test Date'].astype(str).str.startswith('201506')]\r\n\r\ndata_68 = data_201506.append(data_201508)\r\n\r\nwriter = pd.ExcelWriter(\"C:\\\\test-output.xlsx\", engine = 'openpyxl')\r\ndata_68.to_excel(writer, \"Sheet1\", index = False)\r\nwriter.save()\r\nBut when I applied them to a larger file, ~600,000 rows with 25 columns (65 MB in file size), it returns error message like below:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Python27\\Working Scripts\\LL move pick wanted ATA in months.py\", line 15, in <module>\r\n    writer.save()\r\n  File \"C:\\Python27\\lib\\site-packages\\pandas\\io\\excel.py\", line 732, in save\r\n    return self.book.save(self.path)\r\n  File \"C:\\Python27\\lib\\site-packages\\openpyxl\\workbook\\workbook.py\", line 263, in save\r\n    save_workbook(self, filename)\r\n  File \"C:\\Python27\\lib\\site-packages\\openpyxl\\writer\\excel.py\", line 239, in save_workbook\r\n    writer.save(filename, as_template=as_template)\r\n  File \"C:\\Python27\\lib\\site-packages\\openpyxl\\writer\\excel.py\", line 222, in save\r\n    self.write_data(archive, as_template=as_template)\r\n  File \"C:\\Python27\\lib\\site-packages\\openpyxl\\writer\\excel.py\", line 80, in write_data\r\n    self._write_worksheets(archive)\r\n  File \"C:\\Python27\\lib\\site-packages\\openpyxl\\writer\\excel.py\", line 163, in _write_worksheets\r\n    xml = sheet._write(self.workbook.shared_strings)\r\n  File \"C:\\Python27\\lib\\site-packages\\openpyxl\\worksheet\\worksheet.py\", line 776, in _write\r\n    return write_worksheet(self, shared_strings)\r\n  File \"C:\\Python27\\lib\\site-packages\\openpyxl\\writer\\worksheet.py\", line 263, in write_worksheet\r\n    xf.write(worksheet.page_breaks.to_tree())\r\n  File \"src/lxml/serializer.pxi\", line 1016, in lxml.etree._FileWriterElement.__exit__ (src\\lxml\\lxml.etree.c:142025)\r\n  File \"src/lxml/serializer.pxi\", line 904, in lxml.etree._IncrementalFileWriter._write_end_element (src\\lxml\\lxml.etree.c:140218)\r\n  File \"src/lxml/serializer.pxi\", line 999, in lxml.etree._IncrementalFileWriter._handle_error (src\\lxml\\lxml.etree.c:141711)\r\n  File \"src/lxml/serializer.pxi\", line 195, in lxml.etree._raiseSerialisationError (src\\lxml\\lxml.etree.c:131087)\r\nlxml.etree.SerialisationError: IO_WRITE\r\nDoes it mean the computer is not good enough (8GB, Win10)? Is there a way to optimize the code (for example, consume less memory)? Thank you.\r\n\r\nbtw: Question similiar to I/O Error while saving Excel file - Python but no solution...", "pub_date": "2018-10-23T10:05:53.073Z", "user": ["root"], "votes": 1, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 33, "fields": {"header": "PDF in Python Request", "content": "I have problem with sending a pdf in python post request. My server only supports \"form-data\" and not JSONHere is my code:import requestsfrom requests.auth import HTTPBasicAuthimport osimport jsonurl = \"myUrl\"files ={'fileUpload': open(os.path.join('_my_path', 'my_file.pdf'), 'rb')}payload = \"--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"integrationClass\\\"\\r\\n\\r\\nBPMOnline\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"SITE\\\"\\r\\n\\r\\n21218\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"PROCESS_NAME\\\"\\r\\n\\r\\ncreate\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"DOCUMENT_ID\\\"\\r\\n\\r\\ndoc bpmonline create\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"DOCUMENT_TYPE\\\"\\r\\n\\r\\nsample\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"CLIENT_NAME\\\"\\r\\n\\r\\ncname\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"CLIENT_ID\\\"\\r\\n\\r\\n45678\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"USER\\\"\\r\\n\\r\\nadmin\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"fileUpload\\\"; filename=\\\"download.pdf\\\"\\r\\nContent-Type: application/pdf\\r\\n\\r\\n\\r\\n--my_boundary\\r\\nContent-Disposition: form-data; name=\\\"uuid\\\"\\r\\n\\r\\n\\r\\n--my_boundary--\"headers = {    'content-type': \"multipart/form-data; boundary=my_boundary\",    'cache-control': \"no-cache\",    }response = requests.post(url, data=payload,files=files, headers=headers)print(response.text)ERROR is: \"ValueError: Data must not be a string.\"", "pub_date": "2018-10-23T10:07:08.197Z", "user": ["user54"], "votes": 0, "tag": [7, 24]}}, {"model": "stack.question", "pk": 34, "fields": {"header": "Wireshark malformed packet PN-RT", "content": "I am trying with that codes to comunicate with Ethernet/Profinet protocol. I try one more time and finally i found that type of codes. But when i run to the program with that line:sudo python3 discovery.pyAnd i didnt get any error. My programme running but when i watching the wireshark side my connection information said:Wireshark malformed packet PN-RTYes it know that is Profinet protocol, but why is the malformed ? How can i fix ?That is my python code: discover.py#!/usr/bin/env pythonimport binasciifrom socket import *from fcntl import ioctlimport structimport fcntl, structvalue='!6s6sH's=socket(AF_PACKET, SOCK_RAW)s.bind(('enp2s0',1))class EtherPacket: def __init__(self, dst='25:36:73:32:74:48', src='c3:82:c5:b8:c2:81', protocol=0x8892):  self.dst = dst                # Destination MAC  self.src = src                # Source MAC  self.protocol = protocol      # Protocol Types  self.raw   =\"\"          # Raw Data  self.assemble_eth_feilds() def assemble_eth_feilds(self):  # Assemble All Feilds Of Ether Packet  self.raw = struct.pack( \\      value.encode('ascii'),\\      binascii.unhexlify(self.dst.replace(\":\",\"\")),\\      binascii.unhexlify(self.src.replace(\":\",\"\")),\\      self.protocol,\\      )  return self.rawdef main(): pkt = EtherPacket() s.sendto(pkt.raw, ('enp2s0' , 0 ))if __name__=='__main__':   main()", "pub_date": "2018-10-23T10:07:54.163Z", "user": ["user54"], "votes": 1, "tag": [7, 8]}}, {"model": "stack.question", "pk": 35, "fields": {"header": "calculate root-mean-squared-error of regression in bouts", "content": "lets assume that I get the following pandas dataframe for my regression analysis.import pandasimport mathimport numpydf = pandas.DataFrame(numpy.random.randint(0,100,size=(100, 2)), columns=['labels','predictions'])I would like now to calculate the RMSE asmath.sqrt(numpy.mean((df[\"predictions\"] - df[\"lables\"]) ** 2)) for values of the labels in interval of 7Hereby a very ugly code that does the job...it would be nice if you help me to pythonize it...# define stepstep = 7# initialize counteridx = 0# initialize empty dataframermse = pandas.DataFrame(columns=['bout' , 'rmse'],index=range(0,len(range(int(df['labels'].min())+step,int(df['labels'].max()),step))))# start loop to calculate rmse every 7 unitsfor i in range(int(df['labels'].min())+step,int(df['labels'].max()),step):    # select values in interval    df_bout = df[(df['labels']>=i-step) & (df['labels']<i)]    # calculate rmse in interval    rmse.loc[idx] = [str(i-step)+'-'+str(i),math.sqrt(numpy.mean((df_bout.predictions - df_bout.labels) ** 2))]    # increment counter    idx = idx + 1", "pub_date": "2018-10-23T10:08:29.254Z", "user": ["u5"], "votes": 0, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 36, "fields": {"header": "Unable to stream frames from camera to QML using PyQt5", "content": "I am using PyQT5. I want to send frames from Opencv to QML using QQuickPaintedItem. I wrote a sample implementation here. I cant seem to find why the paint event is called only once, only when the application is loading. It is painting only one frame from the camera to the QML component and the self.update() is not calling paint event.from OpenGL import GLfrom PyQt5.QtQuick import QQuickPaintedItem, QQuickViewfrom PyQt5.QtGui import QPainter, QPixmap, QImagefrom PyQt5.QtQml import qmlRegisterTypeimport sysfrom PyQt5.QtGui import QColorfrom PyQt5.QtCore import QUrl,QObject,pyqtSignalimport cv2.cv2 as cv2from PyQt5.QtWidgets import QApplicationclass ImageWriter(QQuickPaintedItem):    cam_frame = None    def __init__(self, *args, **kwargs):        super(ImageWriter, self).__init__(*args, **kwargs)                self.setRenderTarget(QQuickPaintedItem.FramebufferObject)     def paint(self, painter):        print(ImageWriter.cam_frame)        painter.drawPixmap(0,0,ImageWriter.cam_frame)    def update_frame(self,frame):        frame = cv2.resize(frame, (700, 500), cv2.INTER_AREA)        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)        frame = QImage(frame, frame.shape[1], frame.shape[0], 17)        ImageWriter.cam_frame = QPixmap.fromImage(frame)         self.update()def get_frames(app):    cap = cv2.VideoCapture(0)    num = 0    imgw = ImageWriter()    while True:        while num != 30:            _ , bgframe = cap.read()            num += 1        _ , frame = cap.read()        imgw.update_frame(frame)                    print(\"get frames\")         app.processEvents()if __name__ == '__main__':    app = QApplication(sys.argv)     qmlRegisterType(ImageWriter, \"imageWriter\", 1, 0, \"ImageWriter\")    view = QQuickView()    view.setSource(QUrl('test.qml'))    rootObject = view.rootObject()    view.show()    get_frames(app)    sys.exit(app.exec_())Here is the QML i wrote for this,import QtQuick 2.0import imageWriter 1.0Item {    width: 800    height: 600    ImageWriter  {        id : imageWriter        width : 800        height : 600    }}I am quite not able to get why the paint event is not called by self.update() . I cant use QWidgets, i have to use this. Is there something i am missing out here ?", "pub_date": "2018-10-23T10:09:20.326Z", "user": ["u4"], "votes": -1, "tag": [8, 25]}}, {"model": "stack.question", "pk": 37, "fields": {"header": "Check if a point is in a rotated rectangle (C#) Ask Question", "content": "I have a program in C# (Windows Forms) which draws some rectangles on a picturebox. They can be drawn at an angle too (rotated).\r\n\r\nI know each of the rectangles' start point (upper-left corner), their size(width+height) and their angle. Because of the rotation, the start point is not necessarely the upper-left corner, but that does not matter here. Then when I click the picturebox, I need to check in which rectangle (if any) I have clicked.\r\n\r\nSo I need some way of checking if a point is in a rectangle, but I also need to take into account the rotation of each rectangle. Does anybody know of a way to do this in C#?", "pub_date": "2018-10-23T10:10:32.718Z", "user": ["root"], "votes": -1, "tag": [19, 26, 27]}}, {"model": "stack.question", "pk": 38, "fields": {"header": "How to calculate rotation angle from rectangle points?", "content": "I have 4 points 1,2,3,4 that closes a rectangle.The points are in a array in this following way: x1 y1 x2 y2 x3 y3 x4 y4The problem I have is that the rectangle can be rotated in a angle.How can I calculate the original points (gray outline), and the angle?I'm trying to reproduce this effect in javascript+css3-transform, so I need to first know the straight dimensions and then rotate with the css.I just know if the rectangle is straight by comparing points e.g. y1==y2if(x1==x4 && x2==x3 && y1==y2 && y4==y3){    rectangle.style.top = y1;    rectangle.style.left = x1;    rectangle.style.width = x2-x1;    rectangle.style.height = y4-y1;    rectangle.style.transform = \"rotate(?deg)\";}", "pub_date": "2018-10-23T10:12:17.007Z", "user": ["u3"], "votes": 0, "tag": [19, 28, 29]}}, {"model": "stack.question", "pk": 39, "fields": {"header": "Create a column that has the same length of the longest column in the data at the same time", "content": "I have the following data:data = [[1,2,3], [1,2,3,4,5], [1,2,3,4,5,6,7]]dataFrame = pandas.DataFrame(data).transpose()Output:     0    1    20  1.0  1.0  1.01  2.0  2.0  2.02  3.0  3.0  3.03  NaN  4.0  4.04  NaN  5.0  5.05  NaN  NaN  6.06  NaN  NaN  7.0Is it possible to create a 4th column AT THE SAME TIME the others columns are created in data, which has the same length as the longest column of this dataframe (3rd one)?The data of this column doesn't matter. Assume it's 8. So this is the desired output can be:     0    1    2    30  1.0  1.0  1.0  8.01  2.0  2.0  2.0  8.02  3.0  3.0  3.0  8.03  NaN  4.0  4.0  8.04  NaN  5.0  5.0  8.05  NaN  NaN  6.0  8.06  NaN  NaN  7.0  8.0In my script the dataframe keeps changing every time. This means the longest columns keeps changing with it.Thanks for reading", "pub_date": "2018-10-23T10:13:40.660Z", "user": ["u2"], "votes": 1, "tag": [7, 8, 21]}}, {"model": "stack.question", "pk": 40, "fields": {"header": "Python pandas rank/sort based on group by of two columns column that differs for each input", "content": "I have the following dataframe:Signature   Genes   Labels  Scores     Annotation   CELF1      AARS    0      -5.439356884 EMPTY      CELF1      AATF    0      -5.882719549 EMPTY      CELF1     ABCF1    0      -6.011462342 EMPTY     HNRNPC      AARS    0      -6.166240409 EMPTY     HNRNPC      AATF    0      -6.432658981 EMPTY   HNRNPC     ABCF1    0      -6.476526092 EMPTY      FUS      AARS    0      -5.646015964 EMPTY      FUS      AATF    0      -6.224914841 EMPTY       FUS     ABCF1    0      -6.395334389 EMPTY     I want to rank my 'Scores' Column based on in a Signature column rank 'Genes' based on Scores column such thatSignature   Genes   Labels  Scores     Annotation   Rank   CELF1     AARS    0    -5.439356884   EMPTY        1  CELF1     AATF    0    -5.882719549   EMPTY        2  CELF1    ABCF1    0    -6.011462342   EMPTY        3  HNRNPC    AARS    0    -6.166240409   EMPTY        1  HNRNPC    AATF    0    -6.432658981   EMPTY        2  HNRNPC    ABCF1   0    -6.476526092   EMPTY        3   FUS      AARS    0    -5.646015964   EMPTY        1   FUS      AATF    0   -6.224914841    EMPTY        2   FUS     ABCF1    0   -6.395334389    EMPTY        3I followed based on this post. My code was something like this:   data=pd.read_csv(\"trial1.csv\",sep='\\t')   data['max_score'] = data.groupby(['Signature','Genes'])['Scores'].transform('max').astype(float)   data['rank']=data.groupby('Signature')['max_score'].rank()However my Scores get ranked based on the absolute values, as follows:  Signature Genes   Labels  Scores       Annotation Rank    CELF1    ABCF1      0    -6.011462342    EMPTY    1   CELF1    AATF       0    -5.882719549    EMPTY    2   CELF1    AARS       0    -5.439356884    EMPTY    3  HNRNPC    ABCF1      0    -6.476526092    EMPTY    1  HNRNPC    AATF       0    -6.432658981    EMPTY    2  HNRNPC    AARS       0    -6.166240409    EMPTY    3   FUS      ABCF1      0    -6.395334389    EMPTY    1   FUS       AATF      0    -6.224914841    EMPTY    2   FUS       AARS      0    -5.646015964    EMPTY    3", "pub_date": "2018-10-23T10:15:12.682Z", "user": ["test_user"], "votes": 1, "tag": [7, 21, 22]}}, {"model": "stack.question", "pk": 41, "fields": {"header": "How can I count repetitions in determinate day?", "content": "cpf  day  startdate              enddate1234  1   08/01/2018 12:50:0     08/01/2018 15:30:01234  1   08/01/2018 14:30:0     08/01/2018 15:40:01234  1   08/01/2018 14:50:0     08/01/2018 15:50:01234  2   08/02/2018 20:20:0     08/02/2018 23:50:01234  2   08/02/2018 22:50:0     08/02/2018 23:50:01235  1   08/01/2018 11:50:0     08/01/2018 15:20:05212  1   08/01/2018 14:50:0     08/01/2018 15:20:0I need to calculate conversation time of cpf column in one day. For example, the first cpf is 1234, so in day 1 this cpf initiate a conversation on 08/01/2018 12:50:0 and the end of conversation was 08/01/2018 15:50:0, what I need is exactly this substraction about enddate - startdate, but disconsidering middle of table like 1234 have in 08/01/2018 three conversations, the subtraction is about first hour of first conversation subtract last hour of last conversation. How can I do this?  cpf  day  startdate              enddate              Time_Conversation    1234  1   08/01/2018 12:50:0     08/01/2018 15:30:0         3:00:0    1234  1   08/01/2018 14:30:0     08/01/2018 15:40:0         3:00:0    1234  1   08/01/2018 14:50:0     08/01/2018 15:50:0         3:00:0    1234  2   08/02/2018 20:20:0     08/02/2018 23:50:0         3:30:0    1234  2   08/02/2018 22:50:0     08/02/2018 23:50:0         3:30:0    1235  1   08/01/2018 11:50:0     08/01/2018 15:20:0         4:30:0    5212  1   08/01/2018 14:50:0     08/01/2018 15:20:0         4:30:0", "pub_date": "2018-10-23T10:15:41.841Z", "user": ["root"], "votes": -1, "tag": [7, 21, 22]}}, {"model": "stack.votequestion", "pk": 1, "fields": {"question": 40, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 2, "fields": {"question": 39, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 3, "fields": {"question": 37, "user": ["root"], "rate_sign": false}}, {"model": "stack.votequestion", "pk": 4, "fields": {"question": 36, "user": ["root"], "rate_sign": false}}, {"model": "stack.votequestion", "pk": 5, "fields": {"question": 34, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 6, "fields": {"question": 29, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 7, "fields": {"question": 32, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 8, "fields": {"question": 22, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 9, "fields": {"question": 19, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 10, "fields": {"question": 23, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 11, "fields": {"question": 21, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 12, "fields": {"question": 20, "user": ["root"], "rate_sign": false}}, {"model": "stack.votequestion", "pk": 13, "fields": {"question": 31, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 14, "fields": {"question": 11, "user": ["root"], "rate_sign": true}}, {"model": "stack.votequestion", "pk": 15, "fields": {"question": 1, "user": ["root"], "rate_sign": false}}, {"model": "stack.votequestion", "pk": 16, "fields": {"question": 23, "user": ["u2"], "rate_sign": false}}, {"model": "stack.voteanswer", "pk": 1, "fields": {"answer": 89, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 2, "fields": {"answer": 79, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 3, "fields": {"answer": 78, "user": ["root"], "rate_sign": false}}, {"model": "stack.voteanswer", "pk": 4, "fields": {"answer": 77, "user": ["root"], "rate_sign": false}}, {"model": "stack.voteanswer", "pk": 5, "fields": {"answer": 71, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 6, "fields": {"answer": 61, "user": ["root"], "rate_sign": false}}, {"model": "stack.voteanswer", "pk": 7, "fields": {"answer": 59, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 8, "fields": {"answer": 49, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 9, "fields": {"answer": 54, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 10, "fields": {"answer": 50, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 11, "fields": {"answer": 37, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 12, "fields": {"answer": 35, "user": ["root"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 13, "fields": {"answer": 60, "user": ["u2"], "rate_sign": false}}, {"model": "stack.voteanswer", "pk": 14, "fields": {"answer": 1, "user": ["user54"], "rate_sign": true}}, {"model": "stack.voteanswer", "pk": 15, "fields": {"answer": 11, "user": ["u2"], "rate_sign": false}}, {"model": "stack.voteanswer", "pk": 16, "fields": {"answer": 16, "user": ["u2"], "rate_sign": false}}, {"model": "stack.tag", "pk": 1, "fields": {"tag": "java"}}, {"model": "stack.tag", "pk": 2, "fields": {"tag": "c++"}}, {"model": "stack.tag", "pk": 3, "fields": {"tag": "performance"}}, {"model": "stack.tag", "pk": 4, "fields": {"tag": "php"}}, {"model": "stack.tag", "pk": 5, "fields": {"tag": "datetime"}}, {"model": "stack.tag", "pk": 6, "fields": {"tag": "react-native"}}, {"model": "stack.tag", "pk": 7, "fields": {"tag": "python"}}, {"model": "stack.tag", "pk": 8, "fields": {"tag": "python-3.x"}}, {"model": "stack.tag", "pk": 9, "fields": {"tag": "nmap"}}, {"model": "stack.tag", "pk": 10, "fields": {"tag": "pymysql"}}, {"model": "stack.tag", "pk": 11, "fields": {"tag": "dictionary"}}, {"model": "stack.tag", "pk": 12, "fields": {"tag": "string"}}, {"model": "stack.tag", "pk": 13, "fields": {"tag": "programming-languages"}}, {"model": "stack.tag", "pk": 14, "fields": {"tag": "porting"}}, {"model": "stack.tag", "pk": 15, "fields": {"tag": "unicode"}}, {"model": "stack.tag", "pk": 16, "fields": {"tag": "open-source"}}, {"model": "stack.tag", "pk": 17, "fields": {"tag": "pydev"}}, {"model": "stack.tag", "pk": 18, "fields": {"tag": "http"}}, {"model": "stack.tag", "pk": 19, "fields": {"tag": "math"}}, {"model": "stack.tag", "pk": 20, "fields": {"tag": "twisted"}}, {"model": "stack.tag", "pk": 21, "fields": {"tag": "dataframe"}}, {"model": "stack.tag", "pk": 22, "fields": {"tag": "pandas"}}, {"model": "stack.tag", "pk": 23, "fields": {"tag": "apache-spark"}}, {"model": "stack.tag", "pk": 24, "fields": {"tag": "request"}}, {"model": "stack.tag", "pk": 25, "fields": {"tag": "qt"}}, {"model": "stack.tag", "pk": 26, "fields": {"tag": "c#"}}, {"model": "stack.tag", "pk": 27, "fields": {"tag": "graphics"}}, {"model": "stack.tag", "pk": 28, "fields": {"tag": "javascript"}}, {"model": "stack.tag", "pk": 29, "fields": {"tag": "css3"}}]